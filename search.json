[{"path":"https://acastroaraujo.github.io/protoClassification/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Andrés Castro Araújo Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"andrés castro araújo. Author, maintainer.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"castro araújo (2025). protoClassification: Prototype Model Classification. R package version 0.1.0, https://github.com/acastroaraujo/protoClassification.","code":"@Manual{,   title = {protoClassification: Prototype Model of Classification},   author = {andrés {castro araújo}},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/acastroaraujo/protoClassification}, }"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"protoclassification","dir":"","previous_headings":"","what":"Prototype Model of Classification","title":"Prototype Model of Classification","text":"Install development version protoClassification GitHub :","code":"# install.packages(\"pak\") pak::pak(\"acastroaraujo/protoClassification\")"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get Started","title":"Prototype Model of Classification","text":"simulate dataset need create decide couple things first. number KK dimensions. marginal probabilities dimension. correlation matrix dimensions. Generate data. parameters stored params attribute output. Verify column means roughly correspond marginal probabilities. order verify data follows correlation structure rho calculate “tetrachoric correlation.” Additional stuff Prototype Classification Model: w vector attention weights k P list prototypes, one per category. g (gamma) sensitivity parameter. Calculate distance similarity one prototype time: Calculate distance, similarity, probabilities multiple prototypes time: consolidate() previous output single data frame easier visualization.","code":"library(protoClassification) set.seed(1) K <- 6 # 1st step marginals <- rbeta(K, 2, 2) # 2nd step rho <- rlkjcorr(1, K, eta = 1) # 3rd step  nms <- paste0(\"x\", 1:K) names(marginals) <- nms dimnames(rho) <- list(nms, nms) set.seed(1) sim_data <- make_binary_data(marginals, rho, obs = 1e3) head(sim_data, n = 10) #>    x1 x2 x3 x4 x5 x6 #> 1   0  0  0  1  1  0 #> 2   1  1  1  1  1  1 #> 3   0  0  1  1  1  0 #> 4   1  1  0  1  1  0 #> 5   0  1  1  1  0  1 #> 6   1  1  0  1  0  0 #> 7   0  0  0  1  1  0 #> 8   1  1  0  1  1  1 #> 9   0  1  1  1  1  0 #> 10  1  1  0  1  1  1 attr(sim_data, \"params\") #> $marginals #>        x1        x2        x3        x4        x5        x6  #> 0.3275025 0.5516990 0.2743131 0.8814780 0.5923401 0.2780523  #>  #> $rho #>             x1           x2          x3         x4           x5          x6 #> x1  1.00000000  0.223148504  0.28872627  0.1545050 -0.017382124  0.35530360 #> x2  0.22314850  1.000000000 -0.08484711 -0.2055278 -0.009983913  0.37405720 #> x3  0.28872627 -0.084847106  1.00000000 -0.7472276  0.341004033  0.08352309 #> x4  0.15450496 -0.205527752 -0.74722765  1.0000000 -0.200619041 -0.33781820 #> x5 -0.01738212 -0.009983913  0.34100403 -0.2006190  1.000000000 -0.03222531 #> x6  0.35530360  0.374057201  0.08352309 -0.3378182 -0.032225308  1.00000000 colMeans(sim_data) #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 psych::tetrachoric(sim_data)$rho #>             x1          x2          x3         x4          x5          x6 #> x1  1.00000000  0.23375492  0.28118697  0.1442114 -0.01192531  0.40365755 #> x2  0.23375492  1.00000000 -0.13315127 -0.1448709  0.03404136  0.38467926 #> x3  0.28118697 -0.13315127  1.00000000 -0.7612102  0.40485490  0.07792155 #> x4  0.14421140 -0.14487091 -0.76121019  1.0000000 -0.31759978 -0.34664697 #> x5 -0.01192531  0.03404136  0.40485490 -0.3175998  1.00000000 -0.08953172 #> x6  0.40365755  0.38467926  0.07792155 -0.3466470 -0.08953172  1.00000000 set.seed(1) w <- runif(K) w <- w / sum(w) g <- 10 d <- calculateDistSim(   P = rep(1, K),    w = w,    data = sim_data,    g = g )  str(d) #> 'data.frame':    1000 obs. of  2 variables: #>  $ distance  : num  0.655 0 0.477 0.457 0.145 ... #>  $ similarity: num  0.00143 1 0.00846 0.01035 0.23423 ... prototypes <- list(   P1 = rep(1, K),   P2 = rep(0, K),   P3 = rep(1:0, K / 2) )  g <- rep(10, 3)  out <- compute(prototypes, w, sim_data, g = g, r = 1) out #>  #> ── Overview ── #>  #> ── Output: #>  $ distance     :1000 obs. of  3 variables: #>  $ similarity   :1000 obs. of  3 variables: #>  $ probabilities:1000 obs. of  3 variables: #>  $ data         :1000 obs. of  6 variables: #>  #> ── Prototypes: #>  $ P1: num [1:6] 1 1 1 1 1 1 #>  $ P2: num [1:6] 0 0 0 0 0 0 #>  $ P3: int [1:6] 1 0 1 0 1 0 #>  #> ── Distance: #> Manhattan (r = 1) #>  #> ── Sensitivity: #> g1 g2 g3  #> 10 10 10 #>  #> ── Attention Weights: #>    w1    w2    w3    w4    w5    w6  #> 0.082 0.116 0.178 0.282 0.063 0.279 #>  #> ── Marginal Probabilities, or `colMeans(.$data)` #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 d <- consolidate(out) str(d) #> 'data.frame':    1000 obs. of  15 variables: #>  $ prob1: num  0.0379 0.9988 0.212 0.5783 0.998 ... #>  $ prob2: num  8.45e-01 4.53e-05 1.34e-01 2.45e-01 8.26e-04 ... #>  $ prob3: num  0.11692 0.00115 0.65354 0.17654 0.00115 ... #>  $ sim1 : num  0.00143 1 0.00846 0.01035 0.23423 ... #>  $ sim2 : num  3.18e-02 4.54e-05 5.36e-03 4.39e-03 1.94e-04 ... #>  $ sim3 : num  0.0044 0.001149 0.026083 0.003159 0.000269 ... #>  $ dist1: num  0.655 0 0.477 0.457 0.145 ... #>  $ dist2: num  0.345 1 0.523 0.543 0.855 ... #>  $ dist3: num  0.543 0.677 0.365 0.576 0.822 ... #>  $ x1   : int  0 1 0 1 0 1 0 1 0 1 ... #>  $ x2   : int  0 1 0 1 1 1 0 1 1 1 ... #>  $ x3   : int  0 1 1 0 1 0 0 0 1 0 ... #>  $ x4   : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ x5   : int  1 1 1 1 0 0 1 1 1 1 ... #>  $ x6   : int  0 1 0 0 1 0 0 1 0 1 ..."},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"compositional-effects","dir":"","previous_headings":"","what":"Compositional Effects","title":"Prototype Model of Classification","text":"relevant piece information coming compute() function .$probabilities object. can classify row simulated dataset get conditional probabilities KK feature. two functions calculate compositional effects one simulations. conditionalProbsWhichMax() conditionalProbsSample() Alternatively, ’s easier use summary() function. point compare different probabilities across different parameters values (.e., compositional effects). example: : Figure “r = 1” “r = 2” matters. seems Manhattan distance used underlying data binary. Since ’m using binary data simulations, seems doesn’t matter, right? Figure best way measure compositional effects (e.g., relative risk ratio, difference probabilities)","code":"out$probabilities |>    head(n = 10) #>            P1           P2          P3 #> 1  0.03793516 8.451456e-01 0.116919205 #> 2  0.99880696 4.534577e-05 0.001147689 #> 3  0.21204400 1.344193e-01 0.653536676 #> 4  0.57832896 2.451337e-01 0.176537365 #> 5  0.99802732 8.258837e-04 0.001146794 #> 6  0.35850294 5.320625e-01 0.109434541 #> 7  0.03793516 8.451456e-01 0.116919205 #> 8  0.99726291 1.591178e-03 0.001145915 #> 9  0.73097337 4.589391e-02 0.223132720 #> 10 0.99726291 1.591178e-03 0.001145915 summary(out) #>  #> ── Category Prevalence, or `colMeans(object$probabilities)` #>    P1    P2    P3  #> 0.388 0.436 0.176 #>  #> ── Conditional Probabilities, or `lapply(conditionalProbsSample(object), colMeans)` #> $`1` #>    x1    x2    x3    x4    x5    x6  #> 0.523 0.780 0.328 0.933 0.617 0.626  #>  #> $`2` #>    x1    x2    x3    x4    x5    x6  #> 0.130 0.430 0.058 0.947 0.482 0.038  #>  #> $`3` #>    x1    x2    x3    x4    x5    x6  #> 0.377 0.362 0.690 0.705 0.786 0.088 set.seed(1)  w_unif <- temperature(w, 5) # make weights more uniform w_unif #> [1] 0.1484224 0.1587893 0.1730981 0.1898107 0.1404808 0.1893986  out <- compute(prototypes, w_unif, sim_data, g, r = 1)  summary(out) #>  #> ── Category Prevalence, or `colMeans(object$probabilities)` #>    P1    P2    P3  #> 0.376 0.449 0.175 #>  #> ── Conditional Probabilities, or `lapply(conditionalProbsSample(object), colMeans)` #> $`1` #>    x1    x2    x3    x4    x5    x6  #> 0.555 0.847 0.335 0.920 0.683 0.569  #>  #> $`2` #>    x1    x2    x3    x4    x5    x6  #> 0.094 0.406 0.073 0.944 0.403 0.098  #>  #> $`3` #>    x1    x2    x3    x4    x5    x6  #> 0.429 0.302 0.659 0.739 0.857 0.096  w2 <- vector(\"double\", length(w)) # all attention on dimension 2 w2[[2]] <- 1 w2 #> [1] 0 1 0 0 0 0  out <- compute(prototypes, w2, sim_data, g, r = 1) summary(out) #>  #> ── Category Prevalence, or `colMeans(object$probabilities)` #>    P1    P2    P3  #> 0.554 0.223 0.223 #>  #> ── Conditional Probabilities, or `lapply(conditionalProbsSample(object), colMeans)` #> $`1` #>    x1    x2    x3    x4    x5    x6  #> 0.386 1.000 0.242 0.881 0.597 0.366  #>  #> $`2` #>    x1    x2    x3    x4    x5    x6  #> 0.252 0.000 0.317 0.921 0.577 0.162  #>  #> $`3` #>    x1    x2    x3    x4    x5    x6  #> 0.250 0.000 0.311 0.922 0.576 0.161"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate distances and similarity from features to prototype — calculateDistSim","title":"Calculate distances and similarity from features to prototype — calculateDistSim","text":"Calculate distances similarity features prototype","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate distances and similarity from features to prototype — calculateDistSim","text":"","code":"calculateDistSim(P, w, data, g, r = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate distances and similarity from features to prototype — calculateDistSim","text":"P K-sized vector binary features (.e., prototype) w K-sized vector attention weights data data frame, returned `make_data()` function g sensitivity parameter, number larger zero r type distance, 1 Manhattan, 2 Euclidean","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate distances and similarity from features to prototype — calculateDistSim","text":"data frame distance similarity","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate distance, similarity, and membership probabilities — compute","title":"Calculate distance, similarity, and membership probabilities — compute","text":"Calculate distance, similarity, membership probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate distance, similarity, and membership probabilities — compute","text":"","code":"compute(prototypes, w, data, g, r = 1L)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate distance, similarity, and membership probabilities — compute","text":"prototypes list prototypes, .e., K-sized vectors binary features. w K-sized vector attention weights data data frame, returned `make_data()` function g sensitivity parameter, number larger zero r type distance, 1 Manhattan, 2 Euclidean","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate distance, similarity, and membership probabilities — compute","text":"`prototype` object. list probabilities, similarities,  distances, data used calculate .","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Conditional Probabilities for K Features — conditionalProbsSample","title":"Get Conditional Probabilities for K Features — conditionalProbsSample","text":"Get Conditional Probabilities K Features","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Conditional Probabilities for K Features — conditionalProbsSample","text":"","code":"conditionalProbsSample(x, s = 500)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Conditional Probabilities for K Features — conditionalProbsSample","text":"x `prototype` object created `compute()` function. s number draws sample `.$probabilities` object created `compute()` function","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Conditional Probabilities for K Features — conditionalProbsSample","text":"list conditional probabilities; e.g., `Pr(K = 1 | C = 1)`","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsWhichMax.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Conditional Probabilities for K Features — conditionalProbsWhichMax","title":"Get Conditional Probabilities for K Features — conditionalProbsWhichMax","text":"Get Conditional Probabilities K Features","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsWhichMax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Conditional Probabilities for K Features — conditionalProbsWhichMax","text":"","code":"conditionalProbsWhichMax(x)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsWhichMax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Conditional Probabilities for K Features — conditionalProbsWhichMax","text":"x `prototype` object created `compute()` function.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsWhichMax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Conditional Probabilities for K Features — conditionalProbsWhichMax","text":"list conditional probabilities; e.g., `Pr(K = 1 | C = 1)`","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":null,"dir":"Reference","previous_headings":"","what":"Consolidate computation into a single data frame — consolidate","title":"Consolidate computation into a single data frame — consolidate","text":"Consolidate computation single data frame","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consolidate computation into a single data frame — consolidate","text":"","code":"consolidate(x)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consolidate computation into a single data frame — consolidate","text":"x `prototype` object created `compute()` function.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consolidate computation into a single data frame — consolidate","text":"data frame","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Binary Data — make_binary_data","title":"Make Binary Data — make_binary_data","text":"Make Binary Data","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Binary Data — make_binary_data","text":"","code":"make_binary_data(marginals, rho, obs = 1000)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Binary Data — make_binary_data","text":"marginals K-sized vector marginal probabilities rho correlation matrix obs number rows dataset","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Binary Data — make_binary_data","text":"matrix simulated observations","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make Binary Data — make_binary_data","text":"","code":"K <- 8 marginals <- rbeta(K, 2, 3) rho <- rlkjcorr(1, K, eta = 1 / 4) out <- make_binary_data(marginals, rho) head(out) #>   x1 x2 x3 x4 x5 x6 x7 x8 #> 1  1  1  0  0  0  1  0  0 #> 2  0  0  0  0  1  1  0  1 #> 3  0  1  0  0  0  1  0  1 #> 4  0  0  0  1  1  0  0  0 #> 5  0  0  0  1  1  0  0  0 #> 6  1  0  0  0  1  0  0  0 colMeans(out) #>    x1    x2    x3    x4    x5    x6    x7    x8  #> 0.109 0.465 0.031 0.388 0.541 0.736 0.056 0.355  marginals #> [1] 0.11944329 0.46556715 0.02627365 0.39860397 0.56347394 0.70392211 0.06967656 #> [8] 0.33971610"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":null,"dir":"Reference","previous_headings":"","what":"LKJ distribution — rlkjcorr","title":"LKJ distribution — rlkjcorr","text":"LKJ distribution","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LKJ distribution — rlkjcorr","text":"","code":"rlkjcorr(n, K, eta = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"LKJ distribution — rlkjcorr","text":"functions come Richard McElreath's `rethinking` package , judging source code, seems got Ben Goodrich.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LKJ distribution — rlkjcorr","text":"n number draws K number rows columns matrix eta prior, eta increases mass placed identity matrices","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LKJ distribution — rlkjcorr","text":"matrix list matrices","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":null,"dir":"Reference","previous_headings":"","what":"Temperature Scaling — temperature","title":"Temperature Scaling — temperature","text":"Temperature Scaling","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temperature Scaling — temperature","text":"","code":"temperature(w, temp = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temperature Scaling — temperature","text":"w numeric vector probabilities (must sum 1) temp numeric, temperature parameter - temp > 1: makes distribution uniform - temp < 1: makes distribution less uniform - temp = 1: change","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temperature Scaling — temperature","text":"numeric vector temperature-scaled probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temperature Scaling — temperature","text":"","code":"w <- runif(10) w <- w / sum(w)  temperature(w, temp = 0) #>  [1] 0 0 0 1 0 0 0 0 0 0 temperature(w, temp = 0.5) #>  [1] 0.040633604 0.001128874 0.022777025 0.300567986 0.025898944 0.123899178 #>  [7] 0.297737610 0.003878661 0.015603396 0.167874721 temperature(w, temp = 1) #>  [1] 0.07783426 0.01297331 0.05827424 0.21168959 0.06213970 0.13591343 #>  [7] 0.21069052 0.02404745 0.04823227 0.15820522"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform correlation — transform_rho","title":"Transform correlation — transform_rho","text":"Transform correlation","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform correlation — transform_rho","text":"","code":"transform_rho(rho, el)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform correlation — transform_rho","text":"rho correlation matrix el K--3 matrix first two columns row column indicators; third column new value.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform correlation — transform_rho","text":"transformed correlation matrix, adjusted    \"positive definite\"","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform correlation — transform_rho","text":"","code":"rho <- rlkjcorr(n = 1, K = 4, eta = 1)  el <- rbind(   c(i = 1, j = 2, r = +0.7), ## set corr between x1 and x2 as 0.7   c(i = 3, j = 4, r = -0.5)  ## set corr between x3 and x4 as -0.5 )  out <- transform_rho(rho, el) #> iterations: 14 #> converged: TRUE  round(rho, 2) #>      [,1]  [,2]  [,3]  [,4] #> [1,] 1.00  0.10  0.24  0.03 #> [2,] 0.10  1.00  0.24 -0.80 #> [3,] 0.24  0.24  1.00 -0.16 #> [4,] 0.03 -0.80 -0.16  1.00 round(out, 2) #>       [,1]  [,2]  [,3]  [,4] #> [1,]  1.00  0.64  0.22 -0.02 #> [2,]  0.64  1.00  0.27 -0.73 #> [3,]  0.22  0.27  1.00 -0.48 #> [4,] -0.02 -0.73 -0.48  1.00"}]
