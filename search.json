[{"path":"https://acastroaraujo.github.io/protoClassification/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Andr√©s Castro Ara√∫jo Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"andr√©s castro ara√∫jo. Author, maintainer.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"castro ara√∫jo (2025). protoClassification: Prototype Model Classification. R package version 0.1.0, https://github.com/acastroaraujo/protoClassification.","code":"@Manual{,   title = {protoClassification: Prototype Model of Classification},   author = {andr√©s {castro ara√∫jo}},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/acastroaraujo/protoClassification}, }"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"protoclassification","dir":"","previous_headings":"","what":"Prototype Model of Classification","title":"Prototype Model of Classification","text":"Install development version protoClassification GitHub :","code":"# install.packages(\"pak\") pak::pak(\"acastroaraujo/protoClassification\")"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get Started","title":"Prototype Model of Classification","text":"simulate dataset need create decide couple things first. number KK dimensions. marginal probabilities dimension. correlation matrix dimensions. Generate data. Note. parameters stored params attribute output. can verify column means roughly correspond marginal probabilities. order verify data follows correlation structure rho calculate ‚Äútetrachoric correlation.‚Äù Additional stuff Prototype Classification Model: w vector attention weights k P list prototypes, one per category. g (gamma) sensitivity parameter. Calculate distance similarity one prototype time: Calculate distance, similarity, probabilities multiple prototypes time: consolidate() previous output single data frame easier visualization. Note. Since binary data implemented, difference Manhattan Euclidean distance!","code":"library(protoClassification) set.seed(1) K <- 6 # 1st step marginals <- rbeta(K, 2, 2) # 2nd step rho <- rlkjcorr(1, K, eta = 1) # 3rd step set.seed(1) sim_data <- make_binary_data(marginals, rho, obs = 1e3) sim_data #>  #> ‚îÄ‚îÄ Data ‚îÄ‚îÄ #>  #> 1000 obs. of  6 variables: #>  $ x1: int  0 1 0 1 0 1 0 1 0 1 ... #>  $ x2: int  0 1 0 1 1 1 0 1 1 1 ... #>  $ x3: int  0 1 1 0 1 0 0 0 1 0 ... #>  $ x4: int  1 1 1 1 1 1 1 1 1 1 ... #>  $ x5: int  1 1 1 1 0 0 1 1 1 1 ... #>  $ x6: int  0 1 0 0 1 0 0 1 0 1 ... #>  #> ‚îÄ‚îÄ Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginal Probabilities: #>   x1   x2   x3   x4   x5   x6  #> 0.33 0.55 0.27 0.88 0.59 0.28 #>  #>  #> ‚îÄ‚îÄ Correlation Matrix: #>       x1    x2    x3    x4    x5    x6 #> x1  1.00  0.22  0.29  0.15 -0.02  0.36 #> x2  0.22  1.00 -0.08 -0.21 -0.01  0.37 #> x3  0.29 -0.08  1.00 -0.75  0.34  0.08 #> x4  0.15 -0.21 -0.75  1.00 -0.20 -0.34 #> x5 -0.02 -0.01  0.34 -0.20  1.00 -0.03 #> x6  0.36  0.37  0.08 -0.34 -0.03  1.00 colMeans(sim_data) #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 psych::tetrachoric(sim_data)$rho #>             x1          x2          x3         x4          x5          x6 #> x1  1.00000000  0.23375492  0.28118697  0.1442114 -0.01192531  0.40365755 #> x2  0.23375492  1.00000000 -0.13315127 -0.1448709  0.03404136  0.38467926 #> x3  0.28118697 -0.13315127  1.00000000 -0.7612102  0.40485490  0.07792155 #> x4  0.14421140 -0.14487091 -0.76121019  1.0000000 -0.31759978 -0.34664697 #> x5 -0.01192531  0.03404136  0.40485490 -0.3175998  1.00000000 -0.08953172 #> x6  0.40365755  0.38467926  0.07792155 -0.3466470 -0.08953172  1.00000000 set.seed(1) w <- runif(K) w <- w / sum(w) g <- 10 d <- calculateDistSim(   P = rep(1, K),    w = w,    data = sim_data,    g = g )  str(d) #> 'data.frame':    1000 obs. of  2 variables: #>  $ distance  : num  0.655 0 0.477 0.457 0.145 ... #>  $ similarity: num  0.00143 1 0.00846 0.01035 0.23423 ... prototypes <- list(   P1 = rep(1, K),   P2 = rep(0, K),   P3 = rep(1:0, K / 2) )  g <- rep(10, 3)  out <- compute(sim_data, prototypes, w, g) out #>  #> ‚îÄ‚îÄ Output ‚îÄ‚îÄ #>  #>  $ distance      1000 obs. of  3 variables #>  $ similarity    1000 obs. of  3 variables #>  $ probabilities 1000 obs. of  3 variables #>  $ data          1000 obs. of  6 variables #>  #> ‚îÄ‚îÄ Prototypes ‚îÄ‚îÄ #>  #>  $ P1: num [1:6] 1 1 1 1 1 1 #>  $ P2: num [1:6] 0 0 0 0 0 0 #>  $ P3: int [1:6] 1 0 1 0 1 0 #>  #> ‚îÄ‚îÄ Distance ‚îÄ‚îÄ #>  #> Manhattan (r = 1) #>  #> ‚îÄ‚îÄ Sensitivity ‚îÄ‚îÄ #>  #> g1 g2 g3  #> 10 10 10 #>  #> ‚îÄ‚îÄ Attention Weights ‚îÄ‚îÄ #>  #>    w1    w2    w3    w4    w5    w6  #> 0.082 0.116 0.178 0.282 0.063 0.279 #>  #> ‚îÄ‚îÄ Marginal Probabilities ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ `colMeans(.$data)` #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 #>  #> ‚îÄ‚îÄ `colMeans(.$probabilities)` #>        C1        C2        C3  #> 0.3883449 0.4360664 0.1755887 d <- consolidate(out) str(d) #> 'data.frame':    1000 obs. of  15 variables: #>  $ prob1: num  0.0379 0.9988 0.212 0.5783 0.998 ... #>  $ prob2: num  8.45e-01 4.53e-05 1.34e-01 2.45e-01 8.26e-04 ... #>  $ prob3: num  0.11692 0.00115 0.65354 0.17654 0.00115 ... #>  $ sim1 : num  0.00143 1 0.00846 0.01035 0.23423 ... #>  $ sim2 : num  3.18e-02 4.54e-05 5.36e-03 4.39e-03 1.94e-04 ... #>  $ sim3 : num  0.0044 0.001149 0.026083 0.003159 0.000269 ... #>  $ dist1: num  0.655 0 0.477 0.457 0.145 ... #>  $ dist2: num  0.345 1 0.523 0.543 0.855 ... #>  $ dist3: num  0.543 0.677 0.365 0.576 0.822 ... #>  $ x1   : int  0 1 0 1 0 1 0 1 0 1 ... #>  $ x2   : int  0 1 0 1 1 1 0 1 1 1 ... #>  $ x3   : int  0 1 1 0 1 0 0 0 1 0 ... #>  $ x4   : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ x5   : int  1 1 1 1 0 0 1 1 1 1 ... #>  $ x6   : int  0 1 0 0 1 0 0 1 0 1 ..."},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"marginal-and-conditional-probabilities","dir":"","previous_headings":"","what":"Marginal and Conditional Probabilities","title":"Prototype Model of Classification","text":"far, single simulation requires marginal probabilities element ùê±\\mathbf{x} specified outset. relevant piece information get compute() function .$probabilities object, calculates probability given individual simulated dataset belong prototype categories. allows us calculate marginal probabilities category. ingenuity, can use information get conditional probabilities . Pr(Xk=1‚à£C=c) \\Pr(X_k = 1 \\mid C = c) Pr(Xk=0‚à£C=c) \\Pr(X_k = 0 \\mid C = c) Pr(C=c‚à£Xk) \\Pr(C = c \\mid X_k) Alternatively, ‚Äôs easier use summary() function extract conditional marginal probabilities.","code":"colMeans(out$data) # cf. `marginals` argument in `make_binary_data()` #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 colMeans(out$probabilities) #>        C1        C2        C3  #> 0.3883449 0.4360664 0.1755887 conditionalProbs(out, \"features\") #>           x1        x2         x3        x4        x5         x6 #> C1 0.5226571 0.7802353 0.32826487 0.9332301 0.6171392 0.62588499 #> C2 0.1302299 0.4297247 0.05791891 0.9465871 0.4820181 0.03806980 #> C3 0.3770770 0.3621551 0.69020964 0.7052639 0.7862111 0.08786438 1 - conditionalProbs(out, \"features\") #>           x1        x2        x3         x4        x5        x6 #> C1 0.4769570 0.2200126 0.6714007 0.06717440 0.3829206 0.3734904 #> C2 0.8703417 0.5706125 0.9425701 0.05316343 0.5189671 0.9620408 #> C3 0.6227137 0.6362298 0.3103042 0.29413893 0.2117976 0.9130266 conditionalProbs(out, type = \"categories\") #> $`Xk=0` #>           C1        C2         C3 #> x1 0.2743383 0.5632908 0.16237092 #> x2 0.1926099 0.5577848 0.24960538 #> x3 0.3591157 0.5664215 0.07446281 #> x4 0.2566337 0.2286733 0.51469307 #> x5 0.3608689 0.5489563 0.09017476 #> x6 0.2001655 0.5788414 0.22099310 #>  #> $`Xk=1` #>           C1         C2         C3 #> x1 0.6236135 0.17344785 0.20293865 #> x2 0.5456643 0.33832130 0.11601444 #> x3 0.4652701 0.09116788 0.44356204 #> x4 0.4029833 0.45951724 0.13749944 #> x5 0.4073537 0.35719728 0.23544898 #> x6 0.8839345 0.06015273 0.05591273 probs <- summary(out) probs #>  #> ‚îÄ‚îÄ Categories ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginals: #>    C1    C2    C3  #> 0.388 0.436 0.176 #>  #> ‚îÄ‚îÄ Conditionals: #> $`Xk=0` #>       C1    C2    C3 #> x1 0.276 0.562 0.162 #> x2 0.193 0.558 0.249 #> x3 0.360 0.565 0.075 #> x4 0.258 0.231 0.511 #> x5 0.362 0.548 0.091 #> x6 0.202 0.578 0.220 #>  #> $`Xk=1` #>       C1    C2    C3 #> x1 0.624 0.173 0.202 #> x2 0.548 0.337 0.116 #> x3 0.467 0.092 0.441 #> x4 0.404 0.458 0.137 #> x5 0.409 0.357 0.234 #> x6 0.884 0.060 0.056 #>  #> ‚îÄ‚îÄ Features ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginals: #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 #>  #> ‚îÄ‚îÄ Conditionals: #>       x1    x2    x3    x4    x5    x6 #> C1 0.523 0.779 0.329 0.933 0.618 0.625 #> C2 0.129 0.429 0.057 0.946 0.480 0.038 #> C3 0.378 0.364 0.691 0.705 0.788 0.088"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"compositional-effects","dir":"","previous_headings":"","what":"Compositional Effects","title":"Prototype Model of Classification","text":"main goal compare different probabilities across different parameters values. particular, can measure ‚Äúcompositional effects‚Äù result different parameter values keeping track conditional probabilities: Pr(ùê±‚à£C,Œ©)\\Pr(\\mathbf{x} \\mid C, \\Omega), Œ©\\Omega short-hand way referring parameters prototype model. provide examples. Changing Œ≥\\gamma increase marginal probabilities second category. compositional effects: Changing ‚Äúattention weights‚Äù 1st, can make attention weights selective, meaning classification becomes rule-like.   change compositional effects make new p(xk‚à£c)p(x_k \\mid c) high xkx_k highly weighted. extreme, attention placed exclusively one feature. expect p(xk‚à£c)p(x_k \\mid c) 1.  Furthermore, marginal probability c1c_1 converge marginal probability feature exclusive attention. Compositional Effects:","code":"set.seed(9) # Basic Workflow ----  K <- 10  obs <- 1e3  # Data ----  mu <- rbeta(K, 2, 2)  rho <- rlkjcorr(1, K, eta = 1)  sim_data <- make_binary_data(mu, rho, obs)  # Prototype Parameters ----  w <- runif(K) w <- w / sum(w)  g <- c(10, 10)  prototypes <- list(   P1 = rep(1, K),   P2 = rep(0, K) )  # Compute ----  out <- compute(sim_data, prototypes, w, g) probs <- summary(out, s = 1e3) # This should make the second category more inclusive new_out <- compute(sim_data, prototypes, w, g = c(10, 5)) new_probs <- summary(new_out, s = 1e3) probs$marginal$categories #>        C1        C2  #> 0.3467094 0.6532906 new_probs$marginal$categories #>        C1        C2  #> 0.1272612 0.8727388 probs$conditional$features #>           x1        x2        x3        x4        x5        x6        x7 #> C1 0.5728644 0.5546241 0.4564499 0.5167535 0.8871769 0.3245671 0.8346980 #> C2 0.1476666 0.1344176 0.4190103 0.4130322 0.5257202 0.1370018 0.8030352 #>           x8        x9       x10 #> C1 0.5830473 0.3673473 0.4692927 #> C2 0.4483320 0.4632084 0.3647565 new_probs$conditional$features #>           x1        x2        x3        x4        x5        x6        x7 #> C1 0.6926339 0.7162739 0.4362536 0.5256324 0.9326090 0.3853025 0.8662932 #> C2 0.2370709 0.2164392 0.4313787 0.4378470 0.6099313 0.1753121 0.8064060 #>           x8        x9       x10 #> C1 0.6368593 0.3008669 0.4785071 #> C2 0.4743415 0.4487705 0.3897002  # diff-in-prob new_probs$conditional$features - probs$conditional$features #>            x1         x2          x3          x4         x5         x6 #> C1 0.11976955 0.16164978 -0.02019631 0.008878864 0.04543211 0.06073539 #> C2 0.08940431 0.08202158  0.01236839 0.024814811 0.08421110 0.03831033 #>             x7         x8          x9         x10 #> C1 0.031595164 0.05381202 -0.06648039 0.009214365 #> C2 0.003370833 0.02600956 -0.01443787 0.024943624 # risk ratio new_probs$conditional$features / probs$conditional$features #>          x1       x2        x3       x4       x5       x6       x7       x8 #> C1 1.209071 1.291458 0.9557535 1.017182 1.051210 1.187127 1.037852 1.092294 #> C2 1.605447 1.610200 1.0295181 1.060080 1.160182 1.279634 1.004198 1.058014 #>           x9      x10 #> C1 0.8190258 1.019635 #> C2 0.9688307 1.068384 w2 <- temperature(w, temp = 1/4) # cf. \"temperature sampling\" barplot(w, names.arg = seq_along(w), main = \"Original Weights\") barplot(w2, names.arg = seq_along(w), main = \"New Weights\") new_out <- compute(sim_data, prototypes, w = w2, g) new_probs <- summary(new_out, s = 1e3) probs$conditional$features #>           x1        x2        x3        x4        x5        x6        x7 #> C1 0.5728644 0.5546241 0.4564499 0.5167535 0.8871769 0.3245671 0.8346980 #> C2 0.1476666 0.1344176 0.4190103 0.4130322 0.5257202 0.1370018 0.8030352 #>           x8        x9       x10 #> C1 0.5830473 0.3673473 0.4692927 #> C2 0.4483320 0.4632084 0.3647565 new_probs$conditional$features #>           x1         x2        x3        x4        x5        x6        x7 #> C1 0.4860178 0.86941998 0.3071452 0.3394442 0.7586206 0.2901795 0.9158345 #> C2 0.2139871 0.03015844 0.4849078 0.4954442 0.6053495 0.1646123 0.7708265 #>           x8        x9       x10 #> C1 0.5976563 0.2572416 0.3823109 #> C2 0.4514389 0.5032435 0.4089434  # diff-in-prob new_probs$conditional$features - probs$conditional$features #>             x1         x2          x3          x4          x5          x6 #> C1 -0.08684659  0.3147958 -0.14930471 -0.17730924 -0.12855632 -0.03438758 #> C2  0.06632044 -0.1042591  0.06589754  0.08241196  0.07962923  0.02761056 #>             x7          x8         x9         x10 #> C1  0.08113647 0.014608959 -0.1101057 -0.08698181 #> C2 -0.03220874 0.003106965  0.0400351  0.04418685 # risk ratio new_probs$conditional$features / probs$conditional$features #>           x1        x2        x3        x4        x5        x6        x7 #> C1 0.8483994 1.5675841 0.6729001 0.6568785 0.8550951 0.8940509 1.0972046 #> C2 1.4491228 0.2243638 1.1572695 1.1995291 1.1514669 1.2015343 0.9598912 #>          x8        x9       x10 #> C1 1.025056 0.7002682 0.8146534 #> C2 1.006930 1.0864300 1.1211407 w2 <- vector(\"double\", length(w)) # all attention on dimension 3 w2[[3]] <- 1 barplot(w2, names.arg = seq_along(w2)) new_out <- compute(sim_data, prototypes, w = w2, g) new_probs <- summary(new_out, s = 1e3)  new_probs$conditional$features #>           x1        x2           x3        x4        x5        x6        x7 #> C1 0.4212941 0.1689949 9.999469e-01 0.5231397 0.6712993 0.2152812 0.7314927 #> C2 0.1989426 0.3644288 2.811951e-05 0.3926105 0.6355607 0.1918985 0.8767538 #>           x8        x9       x10 #> C1 0.4097318 0.3888849 0.3842530 #> C2 0.5598537 0.4612716 0.4137375 new_probs$marginal #> $categories #>        C1        C2  #> 0.4320062 0.5679938  #>  #> $features #>    x1    x2    x3    x4    x5    x6    x7    x8    x9   x10  #> 0.295 0.280 0.432 0.449 0.651 0.202 0.814 0.495 0.430 0.401 # diff-in-prob new_probs$conditional$features - probs$conditional$features #>             x1         x2         x3           x4         x5          x6 #> C1 -0.15157026 -0.3856292  0.5434970  0.006386203 -0.2158776 -0.10928584 #> C2  0.05127596  0.2300112 -0.4189822 -0.020421740  0.1098404  0.05489672 #>             x7         x8           x9         x10 #> C1 -0.10320531 -0.1733156  0.021537656 -0.08503970 #> C2  0.07371856  0.1115218 -0.001936813  0.04898097  # risk ratio new_probs$conditional$features / probs$conditional$features #>           x1        x2           x3        x4        x5        x6        x7 #> C1 0.7354169 0.3047017 2.190705e+00 1.0123583 0.7566691 0.6632874 0.8763561 #> C2 1.3472414 2.7111691 6.710935e-05 0.9505565 1.2089333 1.4007008 1.0917999 #>           x8        x9       x10 #> C1 0.7027419 1.0586302 0.8187918 #> C2 1.2487482 0.9958187 1.1342840"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"back-to-correlations","dir":"","previous_headings":"","what":"Back to Correlations","title":"Prototype Model of Classification","text":"attention placed one feature, like previous example, get see something intuitive compositions features. compare Look original correlation matrix: seems like difference baseline linear function correlations features.  certainly case attention weights spread .  mission find formula explains p(x‚à£c)p(x\\mid c) function simulation parameters!","code":"xCondC1 <- new_probs$conditional$features[\"C1\", ] x <- new_probs$marginal$features  xCondC1 - x ## difference from baseline marginal probability #>          x1          x2          x3          x4          x5          x6  #>  0.12629413 -0.11100510  0.56794688  0.07413969  0.02029934  0.01328124  #>          x7          x8          x9         x10  #> -0.08250726 -0.08526823 -0.04111505 -0.01674697 rho <- attr(new_out$data, \"params\")$rho round(rho[\"x3\", ], 3) #>     x1     x2     x3     x4     x5     x6     x7     x8     x9    x10  #>  0.146 -0.422  1.000  0.269 -0.014 -0.060 -0.270 -0.204 -0.078  0.006 d <- data.frame(corr = rho[\"x3\", ], diff = xCondC1 - x) plot(d) xCondC1 <- probs$conditional$features[\"C1\", ] x <- probs$marginal$features rho <- attr(out$data, \"params\")$rho  d <- data.frame(corr = rho[\"x3\", ], diff = xCondC1 - x) plot(d)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate distances and similarity from features to prototype ‚Äî calculateDistSim","title":"Calculate distances and similarity from features to prototype ‚Äî calculateDistSim","text":"Calculate distances similarity features prototype","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate distances and similarity from features to prototype ‚Äî calculateDistSim","text":"","code":"calculateDistSim(P, w, data, g, r = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate distances and similarity from features to prototype ‚Äî calculateDistSim","text":"P K-sized vector binary features (.e., prototype) w K-sized vector attention weights data data frame, returned `make_data()` function g sensitivity parameter, number larger zero r type distance, 1 Manhattan, 2 Euclidean","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate distances and similarity from features to prototype ‚Äî calculateDistSim","text":"data frame distance similarity","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate distance, similarity, and membership probabilities ‚Äî compute","title":"Calculate distance, similarity, and membership probabilities ‚Äî compute","text":"Calculate distance, similarity, membership probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate distance, similarity, and membership probabilities ‚Äî compute","text":"","code":"compute(data, prototypes, w, g, r = 1L)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate distance, similarity, and membership probabilities ‚Äî compute","text":"data data frame, returned `make_data()` function prototypes list prototypes, .e., K-sized vectors binary features. w K-sized vector attention weights g sensitivity parameter, number larger zero r type distance, 1 Manhattan, 2 Euclidean (irrelevant working binary data).","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate distance, similarity, and membership probabilities ‚Äî compute","text":"`prototype` object. list probabilities, similarities,  distances, data used calculate .","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Conditional Probabilities ‚Äî conditionalProbs","title":"Get Conditional Probabilities ‚Äî conditionalProbs","text":"Get Conditional Probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Conditional Probabilities ‚Äî conditionalProbs","text":"","code":"conditionalProbs(x, type = c(\"features\", \"categories\"), s = 500)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Conditional Probabilities ‚Äî conditionalProbs","text":"x `prototype` object created `compute()` function. type whether \"features\" `Pr(X|C)` \"categories\" `Pr(C|X)` s number draws sample `.$probabilities` object created `compute()` function","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Conditional Probabilities ‚Äî conditionalProbs","text":"list conditional probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Posterior Draws of Conditional Probabilities ‚Äî conditionalProbsSample","title":"Get Posterior Draws of Conditional Probabilities ‚Äî conditionalProbsSample","text":"Get Posterior Draws Conditional Probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Posterior Draws of Conditional Probabilities ‚Äî conditionalProbsSample","text":"","code":"conditionalProbsSample(x, type = c(\"features\", \"categories\"), s = 500)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Posterior Draws of Conditional Probabilities ‚Äî conditionalProbsSample","text":"x `prototype` object created `compute()` function. type whether \"features\" `Pr(X|C)` \"categories\" `Pr(C|X)` s number draws sample `.$probabilities` object created `compute()` function","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Posterior Draws of Conditional Probabilities ‚Äî conditionalProbsSample","text":"list posterior draws","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":null,"dir":"Reference","previous_headings":"","what":"Consolidate computation into a single data frame ‚Äî consolidate","title":"Consolidate computation into a single data frame ‚Äî consolidate","text":"Consolidate computation single data frame","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consolidate computation into a single data frame ‚Äî consolidate","text":"","code":"consolidate(x)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consolidate computation into a single data frame ‚Äî consolidate","text":"x `prototype` object created `compute()` function.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consolidate computation into a single data frame ‚Äî consolidate","text":"data frame","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Binary Data ‚Äî make_binary_data","title":"Make Binary Data ‚Äî make_binary_data","text":"Make Binary Data","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Binary Data ‚Äî make_binary_data","text":"","code":"make_binary_data(marginals, rho, obs = 1000)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Binary Data ‚Äî make_binary_data","text":"marginals K-sized vector marginal probabilities rho correlation matrix obs number rows dataset","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Binary Data ‚Äî make_binary_data","text":"matrix simulated observations","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make Binary Data ‚Äî make_binary_data","text":"","code":"K <- 8 marginals <- rbeta(K, 2, 3) rho <- rlkjcorr(1, K, eta = 1 / 4) out <- make_binary_data(marginals, rho) head(out) #>  #> ‚îÄ‚îÄ Data ‚îÄ‚îÄ #>  #> 6 obs. of  8 variables: #>  $ x1: int  1 0 0 0 0 1 #>  $ x2: int  1 0 1 0 0 0 #>  $ x3: int  0 0 0 0 0 0 #>  $ x4: int  0 0 0 1 1 0 #>  $ x5: int  0 1 0 1 1 1 #>  $ x6: int  1 1 1 0 0 0 #>  $ x7: int  0 0 0 0 0 0 #>  $ x8: int  0 1 1 0 0 0 #>  #>  #> ‚îÄ‚îÄ Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginal Probabilities:  #>   x1   x2   x3   x4   x5   x6   x7   x8  #> 0.12 0.47 0.03 0.40 0.56 0.70 0.07 0.34  #>  #>  #> ‚îÄ‚îÄ Correlation Matrix:  #>       x1    x2    x3    x4    x5    x6    x7    x8 #> x1  1.00 -0.11  0.20  0.07  0.33  0.32  0.07 -0.19 #> x2 -0.11  1.00  0.63 -0.25 -0.59  0.78  0.09  0.66 #> x3  0.20  0.63  1.00 -0.19 -0.09  0.57  0.54  0.42 #> x4  0.07 -0.25 -0.19  1.00  0.35 -0.56 -0.02 -0.54 #> x5  0.33 -0.59 -0.09  0.35  1.00 -0.45  0.12 -0.52 #> x6  0.32  0.78  0.57 -0.56 -0.45  1.00 -0.14  0.58 #> x7  0.07  0.09  0.54 -0.02  0.12 -0.14  1.00  0.22 #> x8 -0.19  0.66  0.42 -0.54 -0.52  0.58  0.22  1.00 colMeans(out) #>    x1    x2    x3    x4    x5    x6    x7    x8  #> 0.109 0.465 0.031 0.388 0.541 0.736 0.056 0.355  marginals #> [1] 0.11944329 0.46556715 0.02627365 0.39860397 0.56347394 0.70392211 0.06967656 #> [8] 0.33971610"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":null,"dir":"Reference","previous_headings":"","what":"LKJ distribution ‚Äî rlkjcorr","title":"LKJ distribution ‚Äî rlkjcorr","text":"LKJ distribution","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LKJ distribution ‚Äî rlkjcorr","text":"","code":"rlkjcorr(n, K, eta = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"LKJ distribution ‚Äî rlkjcorr","text":"functions come Richard McElreath's `rethinking` package , judging source code, seems got Ben Goodrich.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LKJ distribution ‚Äî rlkjcorr","text":"n number draws K number rows columns matrix eta prior, eta increases mass placed identity matrices","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LKJ distribution ‚Äî rlkjcorr","text":"matrix list matrices","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":null,"dir":"Reference","previous_headings":"","what":"Temperature Scaling ‚Äî temperature","title":"Temperature Scaling ‚Äî temperature","text":"Temperature Scaling","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temperature Scaling ‚Äî temperature","text":"","code":"temperature(w, temp = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temperature Scaling ‚Äî temperature","text":"w numeric vector probabilities (must sum 1) temp numeric, temperature parameter - temp > 1: makes distribution uniform - temp < 1: makes distribution less uniform - temp = 1: change","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temperature Scaling ‚Äî temperature","text":"numeric vector temperature-scaled probabilities","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temperature Scaling ‚Äî temperature","text":"","code":"w <- runif(10) w <- w / sum(w)  temperature(w, temp = 0) #>  [1] 0 0 0 1 0 0 0 0 0 0 temperature(w, temp = 0.5) #>  [1] 0.040633604 0.001128874 0.022777025 0.300567986 0.025898944 0.123899178 #>  [7] 0.297737610 0.003878661 0.015603396 0.167874721 temperature(w, temp = 1) #>  [1] 0.07783426 0.01297331 0.05827424 0.21168959 0.06213970 0.13591343 #>  [7] 0.21069052 0.02404745 0.04823227 0.15820522"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform correlation ‚Äî transform_rho","title":"Transform correlation ‚Äî transform_rho","text":"Transform correlation","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform correlation ‚Äî transform_rho","text":"","code":"transform_rho(rho, el)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform correlation ‚Äî transform_rho","text":"rho correlation matrix el K--3 matrix first two columns row column indicators; third column new value.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform correlation ‚Äî transform_rho","text":"transformed correlation matrix, adjusted    \"positive definite\"","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform correlation ‚Äî transform_rho","text":"","code":"rho <- rlkjcorr(n = 1, K = 4, eta = 1)  el <- rbind(   c(i = 1, j = 2, r = +0.7), ## set corr between x1 and x2 as 0.7   c(i = 3, j = 4, r = -0.5)  ## set corr between x3 and x4 as -0.5 )  out <- transform_rho(rho, el) #> iterations: 14 #> converged: TRUE  round(rho, 2) #>      [,1]  [,2]  [,3]  [,4] #> [1,] 1.00  0.10  0.24  0.03 #> [2,] 0.10  1.00  0.24 -0.80 #> [3,] 0.24  0.24  1.00 -0.16 #> [4,] 0.03 -0.80 -0.16  1.00 round(out, 2) #>       [,1]  [,2]  [,3]  [,4] #> [1,]  1.00  0.64  0.22 -0.02 #> [2,]  0.64  1.00  0.27 -0.73 #> [3,]  0.22  0.27  1.00 -0.48 #> [4,] -0.02 -0.73 -0.48  1.00"}]
