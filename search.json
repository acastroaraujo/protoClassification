[{"path":"https://acastroaraujo.github.io/protoClassification/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Andr√©s Castro Ara√∫jo Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/articles/CompositionalEffects.html","id":"changing-gamma","dir":"Articles","previous_headings":"","what":"Changing Œ≥\\gamma","title":"Compositional Effects","text":"Suppose want change Œ≥\\gamma make second prototype inclusive, means gamma lower. expected category marginal probabilities increased C2C_2. can plot compositional effects one two ways. Difference Probabilities. ŒîP=Pr(Xk=xk‚à£C=c,Œ©1)‚àíPr(Xk=xk‚à£C=c,Œ©0) \\Delta P = \\Pr(X_k = x_k \\mid C = c, \\Omega^1) - \\Pr(X_k = x_k \\mid C = c, \\Omega^0) Relative Risk RR=Pr(Xk=xk‚à£C=c,Œ©1)Pr(Xk=xk‚à£C=c,Œ©0) RR = \\frac{\\Pr(X_k = x_k \\mid C = c, \\Omega^1)}{\\Pr(X_k = x_k \\mid C = c, \\Omega^0)} Difference probabilities.  Relative risk ratios.  reference, attention weights prototypes used baseline model: Conclusion. super interesting, result size category 2 larger, compositional effects positive across features. intuitive, category 1 becomes prototypical, category 2 becomes less prototypical, expecting imply compositional effects. Hindsight 20/20! gonna increase size category 1 instead (changing Œ≥\\gammaaccordingly, compositional effects negative across features. , just set new Œ≥\\gammaparameter g = c(5, 10).","code":"effects <- compositionalEffect(baseline, g = c(10, 5)) effects #>  #> ‚îÄ‚îÄ Changed Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Baseline: ‚îÄ‚îÄ #>  #> $g #> g1 g2  #> 10 10 #> ‚îÄ‚îÄ New: ‚îÄ‚îÄ #> $g #> g1 g2  #> 10  5 #> ‚îÄ‚îÄ Category Marginal Probabilities ‚îÄ‚îÄ #> ‚îÄ‚îÄ Baseline: #>    C1    C2  #> 0.667 0.333 #>  #> ‚îÄ‚îÄ New: #>    C1    C2  #> 0.348 0.652 #>  #> ‚îÄ‚îÄ Œî Probs ‚îÄ‚îÄ #>  #>       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10 #> C1 0.005 0.093 0.098 0.023 0.100 0.062 0.002 0.010 0.037 0.085 #> C2 0.030 0.122 0.050 0.037 0.161 0.083 0.011 0.018 0.087 0.137 #>  #> ‚îÄ‚îÄ Risk Ratio ‚îÄ‚îÄ #>  #>       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10 #> C1 1.018 1.135 1.330 1.043 1.143 1.081 1.005 1.011 1.070 1.117 #> C2 1.140 1.363 1.577 1.086 1.622 1.159 1.027 1.020 1.281 1.385 plotProbChange(effects$diff) plotRR(effects$rr) round(attr(baseline, \"w\"), 3) #>    w1    w2    w3    w4    w5    w6    w7    w8    w9   w10  #> 0.034 0.128 0.104 0.031 0.172 0.172 0.023 0.152 0.085 0.100 attr(baseline, \"prototypes\") #> $P1 #>  [1] 1 1 1 1 1 1 1 1 1 1 #>  #> $P2 #>  [1] 0 0 0 0 0 0 0 0 0 0"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/CompositionalEffects.html","id":"changing-w","dir":"Articles","previous_headings":"","what":"Changing ww","title":"Compositional Effects","text":"use temperature() function transform weights simple rule. ‚Äôve seen , new marginal distribution C1C_1 simply marginal distribution feature exclusive attention. can plot compositional effects. Difference probabilities.  Relative risk ratios.  See Correlations notebook attempt explanation ‚Äôs going . short, changes reflect underlying correlation structure used make data. still bit mysterious . Alternatively, can make attention weights less selective making distribution weights uniform. can plot compositional effects. Difference probabilities.  Relative risk ratios.","code":"temperature(w, 0) #>  [1] 0 0 0 0 1 0 0 0 0 0 effects <- compositionalEffect(baseline, w = temperature(w, 0)) effects #> ‚îÄ‚îÄ Changed Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Baseline: ‚îÄ‚îÄ #>  #> $w #>    w1    w2    w3    w4    w5    w6    w7    w8    w9   w10  #> 0.034 0.128 0.104 0.031 0.172 0.172 0.023 0.152 0.085 0.100 #> ‚îÄ‚îÄ New: ‚îÄ‚îÄ #> $w #>  w1  w2  w3  w4  w5  w6  w7  w8  w9 w10  #>   0   0   0   0   1   0   0   0   0   0 #> ‚îÄ‚îÄ Category Marginal Probabilities ‚îÄ‚îÄ #> ‚îÄ‚îÄ Baseline: #>    C1    C2  #> 0.667 0.333 #>  #> ‚îÄ‚îÄ New: #>    C1    C2  #> 0.553 0.447 #>  #> ‚îÄ‚îÄ Œî Probs ‚îÄ‚îÄ #>  #>        x1     x2     x3     x4     x5     x6     x7     x8     x9    x10 #> C1  0.065 -0.127 -0.048  0.107  0.300 -0.127 -0.075 -0.065 -0.007 -0.020 #> C2 -0.063  0.246  0.112 -0.107 -0.258  0.218  0.099  0.093  0.065  0.121 #>  #> ‚îÄ‚îÄ Risk Ratio ‚îÄ‚îÄ #>  #>       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10 #> C1 1.232 0.815 0.840 1.201 1.428 0.833 0.832 0.931 0.986 0.972 #> C2 0.703 1.734 2.298 0.752 0.000 1.416 1.235 1.104 1.209 1.339 colMeans(sim_data) #>    x1    x2    x3    x4    x5    x6    x7    x8    x9   x10  #> 0.257 0.569 0.227 0.497 0.553 0.682 0.437 0.926 0.455 0.606 plotProbChange(effects$diff) plotRR(effects$rr) temperature(w, 4) #>  [1] 0.07904069 0.11034916 0.10488838 0.07717698 0.11880957 0.11879810 #>  [7] 0.07226168 0.11517193 0.09969943 0.10380407 effects <- compositionalEffect(baseline, w = temperature(w, 4)) effects #> ‚îÄ‚îÄ Changed Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Baseline: ‚îÄ‚îÄ #>  #> $w #>    w1    w2    w3    w4    w5    w6    w7    w8    w9   w10  #> 0.034 0.128 0.104 0.031 0.172 0.172 0.023 0.152 0.085 0.100 #> ‚îÄ‚îÄ New: ‚îÄ‚îÄ #> $w #>    w1    w2    w3    w4    w5    w6    w7    w8    w9   w10  #> 0.079 0.110 0.105 0.077 0.119 0.119 0.072 0.115 0.100 0.104 #> ‚îÄ‚îÄ Category Marginal Probabilities ‚îÄ‚îÄ #> ‚îÄ‚îÄ Baseline: #>    C1    C2  #> 0.667 0.333 #>  #> ‚îÄ‚îÄ New: #>   C1   C2  #> 0.59 0.41 #>  #> ‚îÄ‚îÄ Œî Probs ‚îÄ‚îÄ #>  #>        x1    x2    x3     x4    x5     x6     x7     x8    x9   x10 #> C1  0.039 0.037 0.026  0.023 0.013 -0.040  0.058 -0.012 0.027 0.036 #> C2 -0.044 0.012 0.002 -0.015 0.062  0.102 -0.079  0.026 0.002 0.018 #>  #> ‚îÄ‚îÄ Risk Ratio ‚îÄ‚îÄ #>  #>       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10 #> C1 1.140 1.053 1.087 1.043 1.019 0.948 1.130 0.988 1.051 1.049 #> C2 0.793 1.037 1.019 0.966 1.239 1.194 0.813 1.029 1.007 1.050 plotProbChange(effects$diff) plotRR(effects$rr)"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/CompositionalEffects.html","id":"adding-a-third-category","dir":"Articles","previous_headings":"","what":"Adding a third category","title":"Compositional Effects","text":"Finally, can add third category see happens. Note adding third category means also add third Œ≥\\gamma, keep magnitude others. expected, original categories become smaller, roughly half. can plot compositional effects. Difference probabilities.  Relative risk ratios.  categories lower prevalence features associated third prototype, higher features associated third prototype (exception x4x_4). ‚Äôs different x4x_4? think ‚Äôs weights. biggest ‚Äúexits‚Äù features larger weights. Lets make third group exclusive increasing size Œ≥\\gamma. can plot compositional effects. Difference probabilities.  Relative risk ratios.  changes direction, smaller. Note related Brubaker‚Äôs ‚ÄúExit, Voice, Gender‚Äù article.","code":"new_prototypes <- list(   P1 = rep(1, K),   P2 = rep(0, K),   P3 = rep(0:1, K / 2) )  new_g <- c(10, 10, 10)  effects <- compositionalEffect(baseline, prototypes = new_prototypes, g = new_g) effects #> ‚îÄ‚îÄ Changed Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Baseline: ‚îÄ‚îÄ #>  #> $P1 #>  [1] 1 1 1 1 1 1 1 1 1 1 #>  #> $P2 #>  [1] 0 0 0 0 0 0 0 0 0 0 #>  #> $g #> g1 g2  #> 10 10 #> ‚îÄ‚îÄ New: ‚îÄ‚îÄ #> $P1 #>  [1] 1 1 1 1 1 1 1 1 1 1 #>  #> $P2 #>  [1] 0 0 0 0 0 0 0 0 0 0 #>  #> $P3 #>  [1] 0 1 0 1 0 1 0 1 0 1 #>  #> $g #> g1 g2 g3  #> 10 10 10 #> ‚îÄ‚îÄ Category Marginal Probabilities ‚îÄ‚îÄ #> ‚îÄ‚îÄ Baseline: #>    C1    C2  #> 0.667 0.333 #>  #> ‚îÄ‚îÄ New: #>    C1    C2    C3  #> 0.377 0.157 0.466 #>  #> ‚îÄ‚îÄ Œî Probs ‚îÄ‚îÄ #>  #>       x1     x2    x3    x4    x5     x6    x7     x8    x9    x10 #> C1 0.058 -0.041 0.059 0.029 0.207 -0.077 0.011 -0.028 0.099  0.029 #> C2 0.069 -0.117 0.010 0.038 0.169 -0.228 0.055 -0.096 0.078 -0.016 #>  #> ‚îÄ‚îÄ Risk Ratio ‚îÄ‚îÄ #>  #>       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10 #> C1 1.209 0.941 1.200 1.055 1.296 0.899 1.025 0.970 1.187 1.040 #> C2 1.325 0.652 1.119 1.089 1.647 0.565 1.131 0.892 1.254 0.956 plotProbChange(effects$diff) plotRR(effects$rr) round(attr(baseline, \"w\"), 3) #>    w1    w2    w3    w4    w5    w6    w7    w8    w9   w10  #> 0.034 0.128 0.104 0.031 0.172 0.172 0.023 0.152 0.085 0.100 new_g <- c(10, 10, 15) effects <- compositionalEffect(baseline, prototypes = new_prototypes, g = new_g) effects #> ‚îÄ‚îÄ Changed Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Baseline: ‚îÄ‚îÄ #>  #> $P1 #>  [1] 1 1 1 1 1 1 1 1 1 1 #>  #> $P2 #>  [1] 0 0 0 0 0 0 0 0 0 0 #>  #> $g #> g1 g2  #> 10 10 #> ‚îÄ‚îÄ New: ‚îÄ‚îÄ #> $P1 #>  [1] 1 1 1 1 1 1 1 1 1 1 #>  #> $P2 #>  [1] 0 0 0 0 0 0 0 0 0 0 #>  #> $P3 #>  [1] 0 1 0 1 0 1 0 1 0 1 #>  #> $g #> g1 g2 g3  #> 10 10 15 #> ‚îÄ‚îÄ Category Marginal Probabilities ‚îÄ‚îÄ #> ‚îÄ‚îÄ Baseline: #>    C1    C2  #> 0.667 0.333 #>  #> ‚îÄ‚îÄ New: #>    C1    C2    C3  #> 0.497 0.227 0.276 #>  #> ‚îÄ‚îÄ Œî Probs ‚îÄ‚îÄ #>  #>       x1     x2    x3    x4    x5     x6     x7     x8    x9    x10 #> C1 0.042 -0.052 0.026 0.029 0.164 -0.059 -0.006 -0.018 0.061  0.008 #> C2 0.046 -0.090 0.015 0.017 0.106 -0.140  0.040 -0.046 0.061 -0.015 #>  #> ‚îÄ‚îÄ Risk Ratio ‚îÄ‚îÄ #>  #>       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10 #> C1 1.150 0.923 1.087 1.054 1.234 0.923 0.986 0.981 1.116 1.011 #> C2 1.214 0.733 1.173 1.039 1.408 0.732 1.096 0.948 1.199 0.959 plotProbChange(effects$diff) plotRR(effects$rr)"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/CompositionalEffects.html","id":"many-comparisons","dir":"Articles","previous_headings":"","what":"Many Comparisons","title":"Compositional Effects","text":"can also many comparisons. ‚Äôll show graph presented INAS varying temperature  now multiple compositional effects:","code":"temps <- seq(2, 0.001, length.out = 12) w_list <- map(temps, \\(x) temperature(w, temp = x)) names(w_list) <- temps  df <- imap_dfr(w_list, function(x, i) {   o <- enframe(x, name = \"k\", value = \"w\")   cbind(temperature = i, o) }) |>   mutate(label = factor(paste0(\"w\", k), levels = paste0(\"w\", 1:K)))  df |>   mutate(temperature = factor(temperature, levels = temps)) |>   ggplot(aes(label, w)) +   geom_segment(aes(y = 0, yend = w)) +   geom_point(shape = 21, fill = \"white\") +   facet_wrap(     ~temperature,     labeller = labeller(temperature = \\(x) {       paste(\"Temp:\", round(as.numeric(x), 3))     }),     scales = \"free_y\"   ) +   labs(x = NULL, y = NULL, title = \"Rule-Like Selective Attention\") out <- map(   w_list,   function(x) {     compositionalEffect(baseline, w = x)   },   .progress = TRUE ) #>  ‚ñ†‚ñ†‚ñ†                                8% |  ETA: 19s #>  ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                         25% |  ETA: 14s #>  ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                       33% |  ETA: 13s #>  ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                  50% |  ETA: 10s #>  ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†             67% |  ETA:  6s #>  ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†        83% |  ETA:  3s  prob_changes <- imap(out, function(x, i) {   output <- x$diff |>     rownames_to_column(\"C\") |>     pivot_longer(!C, names_to = \"x\", values_to = \"probChange\")   output$temperature <- i   output })  bind_rows(prob_changes) |>   mutate(temperature = as.numeric(temperature)) |>   filter(C == \"C1\") |>   mutate(x = factor(x, levels = paste0(\"x\", 1:K))) |>   ggplot(aes(temperature, probChange)) +   geom_point() +   geom_line() +   geom_hline(yintercept = 0, linetype = \"dashed\") +   geom_vline(xintercept = 1, linetype = \"dashed\") +   facet_wrap(~x) rr_changes <- imap(out, function(x, i) {   output <- x$rr |>     rownames_to_column(\"C\") |>     pivot_longer(!C, names_to = \"x\", values_to = \"rrChange\")   output$temperature <- i   output })  bind_rows(rr_changes) |>   mutate(temperature = as.numeric(temperature)) |>   filter(C == \"C1\") |>   mutate(x = factor(x, levels = paste0(\"x\", 1:K))) |>   ggplot(aes(temperature, rrChange)) +   geom_point() +   geom_line() +   geom_vline(xintercept = 1, linetype = \"dashed\") +   geom_hline(yintercept = 1, linetype = \"dashed\") +   facet_wrap(~x)"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/Correlations.html","id":"data-simulation","dir":"Articles","previous_headings":"","what":"Data Simulation","title":"Correlations","text":"order simulate data use paper, generate correlated binary observations two parameters: marginal probabilities ùê±\\mathbf x. correlation structure ùê±\\mathbf x.   Now can simulate data. Note. following probably belongs appendix, since boring. trick take marginal probabilities ùê±\\mathbf x map ‚Äúlatent Normal space‚Äù using quantile function‚Äî.e., inverse standard normal cumulative distribution function. ùõç=Œ¶‚àí1(ùê©) \\boldsymbol \\mu = \\Phi^{-1} (\\mathbf p) used correlation matrix ùêë\\mathbf R Œº\\mu generate 5,000 draws multivariate normal distribution. ùê≥‚àºMVNormal(ùõç,ùêë) \\mathbf z \\sim \\text{MVNormal}\\left(\\boldsymbol \\mu, \\mathbf R \\right) Finally, turn latent values binary features probabilities applying normal cumulative distribution function (CDF) . , probability larger 0.50.5 turn feature one, otherwise turn zero. xk={1ifŒ¶(zk)>0.50ifŒ¶(zk)<0.5 x_k = \\begin{cases} 1 &\\text{} &\\Phi(z_k) > 0.5 \\\\ 0 &\\text{} &\\Phi(z_k) < 0.5 \\end{cases} ‚Äôs . generate correlated binary data. might seem bit weird, common data generation process. calculate ‚Äútetrachoric correlation‚Äù x using psych::tetrachoric(x) find result essentially original correlation matrix ùêë\\mathbf R.","code":"set.seed(3) K <- 12  rho <- rlkjcorr(1, K, eta = 1 / 4) ## use this to generate random correlation matrices marginals <- rbeta(K, 2, 3) # use this to generate random probabilities  corrplot::corrplot.mixed(   rho,   tl.col = \"black\" ) marginals |>   enframe() |>   ggplot(aes(name, value)) +   geom_col(width = 1 / 3) +   labs(x = NULL, y = \"marginal probability\") obs <- 5e3 ## high for precision  set.seed(10) d <- make_binary_data(marginals, rho, obs) params <- get_data_params(d) ## I will use this later. d #>  #> ‚îÄ‚îÄ Data ‚îÄ‚îÄ #>  #> 5000 obs. of  12 variables: #>  $ x1 : int  0 0 0 1 0 0 0 0 0 0 ... #>  $ x2 : int  1 1 1 0 1 0 1 1 1 1 ... #>  $ x3 : int  0 1 0 1 0 0 0 1 1 0 ... #>  $ x4 : int  0 0 0 1 0 0 1 1 1 1 ... #>  $ x5 : int  0 0 1 1 1 1 0 0 0 0 ... #>  $ x6 : int  1 0 0 0 1 1 0 0 0 0 ... #>  $ x7 : int  0 1 0 0 0 0 0 0 0 0 ... #>  $ x8 : int  0 1 0 1 1 1 1 0 1 1 ... #>  $ x9 : int  0 0 0 0 0 1 0 0 0 1 ... #>  $ x10: int  0 0 1 0 0 0 0 1 0 0 ... #>  $ x11: int  0 0 0 0 0 0 1 0 1 1 ... #>  $ x12: int  0 0 0 0 0 0 1 0 0 1 ... #>  #> ‚îÄ‚îÄ Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginal Probabilities: #>   x1   x2   x3   x4   x5   x6   x7   x8   x9  x10  x11  x12  #> 0.32 0.58 0.72 0.61 0.40 0.46 0.20 0.51 0.20 0.21 0.18 0.25 #>  #>  #> ‚îÄ‚îÄ Correlation Matrix: #>        x1    x2    x3    x4    x5    x6    x7    x8    x9   x10   x11   x12 #> x1   1.00 -0.34  0.11  0.01  0.22  0.06 -0.18 -0.42 -0.24  0.35 -0.31 -0.01 #> x2  -0.34  1.00 -0.50  0.03 -0.20 -0.14 -0.22  0.46  0.27 -0.25  0.32  0.16 #> x3   0.11 -0.50  1.00  0.46 -0.08 -0.27  0.07  0.06  0.05 -0.13  0.17  0.24 #> x4   0.01  0.03  0.46  1.00 -0.22 -0.44 -0.49  0.41  0.05  0.03  0.29  0.29 #> x5   0.22 -0.20 -0.08 -0.22  1.00  0.61 -0.06  0.02  0.29 -0.11 -0.06 -0.03 #> x6   0.06 -0.14 -0.27 -0.44  0.61  1.00 -0.05 -0.22 -0.02  0.02  0.18  0.04 #> x7  -0.18 -0.22  0.07 -0.49 -0.06 -0.05  1.00  0.00  0.06 -0.49 -0.35  0.12 #> x8  -0.42  0.46  0.06  0.41  0.02 -0.22  0.00  1.00  0.03 -0.70  0.17  0.39 #> x9  -0.24  0.27  0.05  0.05  0.29 -0.02  0.06  0.03  1.00 -0.18  0.44 -0.16 #> x10  0.35 -0.25 -0.13  0.03 -0.11  0.02 -0.49 -0.70 -0.18  1.00 -0.31 -0.37 #> x11 -0.31  0.32  0.17  0.29 -0.06  0.18 -0.35  0.17  0.44 -0.31  1.00  0.20 #> x12 -0.01  0.16  0.24  0.29 -0.03  0.04  0.12  0.39 -0.16 -0.37  0.20  1.00 mu <- qnorm(marginals, mean = 0, sd = 1) mu #>  [1] -0.48095930  0.20606295  0.59248683  0.27982587 -0.25750144 -0.11024503 #>  [7] -0.82921732  0.03633573 -0.82916828 -0.80761381 -0.89811718 -0.67444162 z <- mvtnorm::rmvnorm(obs, mean = mu, sigma = rho) dim(z) #> [1] 5000   12 x <- stats::pnorm(z) > 0.5 x[] <- as.integer(x) head(x, n = 10) # first 10 rows #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] #>  [1,]    1    0    1    1    0    1    0    0    0     1     1     1 #>  [2,]    0    1    0    1    1    1    0    1    1     0     1     0 #>  [3,]    0    0    1    1    1    0    1    1    0     0     0     0 #>  [4,]    0    0    1    1    1    0    0    0    1     0     1     0 #>  [5,]    1    1    1    1    1    1    0    0    0     1     0     0 #>  [6,]    0    0    1    1    0    0    1    1    1     0     0     1 #>  [7,]    0    0    1    1    1    1    1    0    0     0     0     0 #>  [8,]    0    1    1    1    1    0    1    1    1     0     0     1 #>  [9,]    0    0    1    1    1    1    0    1    0     0     0     0 #> [10,]    0    1    1    0    0    0    1    0    1     0     0     0"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/Correlations.html","id":"prototype-model","dir":"Articles","previous_headings":"","what":"Prototype Model","title":"Correlations","text":"Now just need finish specifying parameters Prototype Model. attention weights ùê∞\\mathbf w (one feature). sensitivity parameters ùõÑ\\boldsymbol \\gamma (one category). prototypes ùê©\\mathbf p (one category). example use vector attention weights basically corresponds ‚Äúrule.‚Äù attention placed single feature get see something intuitive compositions features. now going refer single feature k‚ãÜk^\\star. starters, things. proportion c1c_1 proportion xk‚ãÜx_k^\\star. Pr(C=c1)=Pr(Xk=xk‚ãÜ) \\Pr(C = c_1) = \\Pr(X_k = x_k^\\star) probability xk‚ãÜx_k^\\star given c1c_1 one. Pr(Xk=xk‚ãÜ‚à£C=c1)=1 \\Pr(X_k = x_k^\\star \\mid C = c_1) = 1 intuitive can check : composition features within c1c_1 category basically function marginal probabilities ùê±\\mathbf x correlation matrix ùêë\\mathbf R. expand later. now, can visualize composition features within category.  plot shows change probability Pr(Xk)\\Pr(X_k) Pr(Xk‚à£C)\\Pr(X_k \\mid C). following plot replaces horizontal axis correlations xkx_k ‚Äúexclusive feature‚Äù xk‚ãÜx_k^\\star.  discovery made simulations change probability xkx_k conditioning CC roughly linear function correlation xkx_k xk‚ãÜx_k^\\star. ŒîP=Pr(Xk‚à£C)‚àíPr(Xk) \\Delta P = \\Pr(X_k \\mid C) - \\Pr(X_k)  relationship even cleaner remove œÅk‚ãÜk‚ãÜ\\rho_{k^\\star k^\\star}.","code":"w <- rep(0, K) w[[1]] <- 1  g <- c(10, 10)  prototypes <- list(   P1 = rep(1, K),   P2 = rep(0, K) )  # Compute ----  baseline <- compute(d, prototypes, w, g) baseline #>  #> ‚îÄ‚îÄ Output ‚îÄ‚îÄ #>  #>  $ distance      5000 obs. of  2 variables #>  $ similarity    5000 obs. of  2 variables #>  $ probabilities 5000 obs. of  2 variables #>  $ data          5000 obs. of  12 variables #>  #> ‚îÄ‚îÄ Prototypes ‚îÄ‚îÄ #>  #>  $ P1: num [1:12] 1 1 1 1 1 1 1 1 1 1 ... #>  $ P2: num [1:12] 0 0 0 0 0 0 0 0 0 0 ... #>  #> ‚îÄ‚îÄ Distance ‚îÄ‚îÄ #>  #> Manhattan (r = 1) #>  #> ‚îÄ‚îÄ Sensitivity ‚îÄ‚îÄ #>  #> g1 g2  #> 10 10 #>  #> ‚îÄ‚îÄ Attention Weights ‚îÄ‚îÄ #>  #>  w1  w2  w3  w4  w5  w6  w7  w8  w9 w10 w11 w12  #>   1   0   0   0   0   0   0   0   0   0   0   0 #>  #> ‚îÄ‚îÄ Marginal Probabilities ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ `colMeans(.$data)` #>     x1     x2     x3     x4     x5     x6     x7     x8     x9    x10    x11  #> 0.3168 0.5794 0.7186 0.6100 0.3992 0.4514 0.2086 0.5196 0.1998 0.2128 0.1764  #>    x12  #> 0.2428 #>  #> ‚îÄ‚îÄ `colMeans(.$probabilities)` #>        C1        C2  #> 0.3168166 0.6831834 round(conditionalProbs(baseline, \"features\"), 3) #>    x1    x2    x3   x4    x5    x6    x7    x8    x9   x10   x11   x12 #> C1  1 0.405 0.766 0.61 0.509 0.499 0.152 0.329 0.126 0.328 0.083 0.236 #> C2  0 0.660 0.697 0.61 0.348 0.429 0.235 0.608 0.234 0.160 0.220 0.246 probs <- summary(baseline, s = 5e3) # high s for precision  plot_data <- probs$conditional$features |>   rownames_to_column(\"C\") |>   pivot_longer(!C, names_to = \"x\", values_to = \"conditionalProb\") |>   left_join(enframe(probs$marginal$features, \"x\", \"marginal\")) |>   left_join(enframe(params$rho[which.max(w), ], name = \"x\", value = \"corr\")) |>   mutate(x = factor(x, levels = paste0(\"x\", 1:K))) #> Joining with `by = join_by(x)` #> Joining with `by = join_by(x)`  plot_data |>   ggplot(aes(x, y = marginal)) +   geom_segment(     aes(yend = conditionalProb),     arrow = arrow(length = unit(0.015, \"npc\"))   ) +   facet_wrap(~C) +   labs(     x = NULL,     y = \"probability\",     title = \"Feature Composition\",     subtitle = \"Change in probability after conditioning on C\"   ) plot_data |>   ggplot(aes(corr, marginal)) +   geom_segment(     aes(yend = conditionalProb),     arrow = arrow(length = unit(0.1, \"cm\"))   ) +   geom_vline(xintercept = 0, linetype = \"dashed\") +   facet_wrap(~C) +   labs(     title = \"Change in Probability\",     subtitle = expression(       \"As a function of the Correlation between\" ~ x[k] ~ \"and\" ~ x[k]^\"*\"     ),     x = expression(rho[kk^\"*\"]),     y = \"probability\"   ) plot_data |>    mutate(change = conditionalProb - marginal) |>    ggplot(aes(corr, change)) +    geom_hline(yintercept = 0, linetype = \"dashed\") +   geom_vline(xintercept = 0, linetype = \"dashed\") +   geom_smooth(method = \"lm\", fill = \"skyblue\") +   geom_point() +   facet_wrap(~C) +    labs(     title = \"Change in Probability vs. Correlation\",     y = expression(Delta ~ P), x = expression(rho[kk^\"*\"])   ) #> `geom_smooth()` using formula = 'y ~ x' exclusive_feature <- colnames(baseline$data)[which.max(w)]  plot_data |>    mutate(change = conditionalProb - marginal) |>    filter(x != exclusive_feature) |>    ggplot(aes(corr, change)) +    geom_hline(yintercept = 0, linetype = \"dashed\") +   geom_vline(xintercept = 0, linetype = \"dashed\") +   geom_smooth(method = \"lm\", fill = \"skyblue\") +   geom_point() +   facet_wrap(~C) +    labs(     title = \"Change in Probability vs. Correlation\",     y = expression(Delta ~ P), x = expression(rho[kk^\"*\"])   ) #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/Correlations.html","id":"the-uncorrelated-world","dir":"Articles","previous_headings":"","what":"The Uncorrelated World","title":"Correlations","text":"say change probabilities connected correlations xk‚ãÜx_k^\\star xkx_k, expect see anything generate uncorrelated data, right? Code shown redundant.  Right! Search Simple Function , think function linking p(x‚à£c)p(x \\mid c) parameter values simple case attention given single feature k‚ãÜk^\\star (baseline)? first thing notice distance function simple. goes : dist(ùê±i,ùê©A)=(‚àëk=1Kwk|xik‚àípk|r)1r \\text{dist}(\\mathbf{x}_i, \\mathbf{p}_A) = \\Bigg( \\sum_{k = 1}^K w_k | x_{ik} - p_{k} |^r \\Bigg)^{\\frac{1}{r}} : dist(ùê±i,ùê©A)=(1√ó|xik‚ãÜ‚àípk‚ãÜ|r)1r \\text{dist}(\\mathbf{x}_i, \\mathbf{p}_A) = \\Bigg(  1 \\times | x_{ik}^\\star - p_{k}^\\star |^r \\Bigg)^{\\frac{1}{r}} ‚ãÜ\\star denotes feature single attention rr parameters superfluous data binary, two possible distances: 0 1. equation: S(ùê±i,ùê©A)=exp(‚àíŒ≥‚ãÖdist(ùê±i,ùê©A)) S (\\mathbf{x}_i, \\mathbf{p}_A) = \\exp \\Big(- \\gamma \\cdot \\text{dist} (\\mathbf{x}_i, \\mathbf{p}_A) \\Big) becomes S(ùê±i,ùê©A)={e0ifxk‚ãÜ=1e‚àíŒ≥ifxk‚ãÜ=0 S (\\mathbf{x}_i, \\mathbf{p}_A) = \\begin{cases} e^ 0 & \\text{}  &x_k^\\star=1 \\\\ e^{-\\gamma} & \\text{} &x_k^\\star=0  \\end{cases} probability ‚ààCAi \\C_A, xi‚ãÜ=1x_i^\\star = 1 simply becomes : Pr(‚ààCA)=11+e‚àíŒ≥B+e‚àíŒ≥C‚Ä¶‚èücompeting categories \\Pr(\\C_A) = \\frac{1}{1 + \\underbrace{e^{-\\gamma_B}+ e^{-\\gamma_C} \\dots}_{\\text{competing categories}}} almost close zero xi‚ãÜ=0x_i^\\star = 0. assume Œ≥\\gamma high, expected less exclusionary categories, probability approximately either 0 1. ‚Äôs . law total probability get following: Pr(C=c1)=Pr(C=c1‚à£Xk‚ãÜ=1)‚èû1Pr(Xk‚ãÜ=1)+Pr(C=c1‚à£Xk‚ãÜ=0)‚èû0Pr(Xk‚ãÜ=0)=Pr(Xk‚ãÜ=1) \\begin{align} \\Pr(C = c_1) &= \\overbrace{\\Pr(C = c_1 \\mid X_k^\\star = 1)}^{1} \\Pr(X_k^\\star = 1) + \\overbrace{\\Pr(C = c_1 \\mid X_k^\\star = 0)}^{0} \\Pr(X_k^\\star = 0) \\\\ &= \\Pr(X_k^\\star = 1) \\end{align} want, want Pr(Xj=1‚à£C=c)\\Pr(X_j = 1 \\mid C = c). Thus, can expand thing using law total probability. Pr(Xj=1‚à£C)=Pr(Xj=1‚à£C,Xk‚ãÜ=1)Pr(Xk‚ãÜ=1‚à£C)+Pr(Xj=1‚à£C,Xk‚ãÜ=0)Pr(Xk‚ãÜ=0‚à£C) \\Pr(X_j = 1 \\mid C) = \\Pr(X_j =1 \\mid C, X_k^\\star = 1) \\Pr(X_k^\\star = 1 \\mid C) + \\Pr(X_j = 1 \\mid C, X_k^\\star = 0) \\Pr(X_k^\\star = 0 \\mid C) Given know , XjX_j CC conditionally independent. Xj‚ä•C‚à£Xk‚ãÜ X_j \\perp C \\mid X_k^\\star means Pr(Xj‚à£C,Xk‚ãÜ)=Pr(Xj‚à£Xk‚ãÜ)\\Pr(X_j \\mid C, X_k^\\star) = \\Pr(X_j \\mid X_k^\\star). can rewrite conditional probability (using law total probability) : Pr(Xj=1‚à£C)=Pr(Xj=1‚à£Xk‚ãÜ=1)Pr(Xk‚ãÜ=1‚à£C=c1)+Pr(Xj=1‚à£Xk‚ãÜ=0)Pr(Xk‚ãÜ=0‚à£C=c1) \\Pr(X_j = 1 \\mid C) = \\Pr(X_j = 1 \\mid X_k^\\star = 1) \\Pr(X_k^\\star = 1 \\mid C = c_1) + \\Pr(X_j = 1 \\mid X_k^\\star = 0) \\Pr(X_k^\\star = 0 \\mid C = c_1) Since established high Œ≥\\gamma values: - Pr(Xk‚ãÜ=1‚à£C=c1)‚âà1\\Pr(X_k^\\star = 1 \\mid C = c_1) \\approx 1 Pr(Xk‚ãÜ=0‚à£C=c1)‚âà0\\Pr(X_k^\\star = 0 \\mid C = c_1) \\approx 0 - Pr(Xk‚ãÜ=1‚à£C=c2)‚âà0\\Pr(X_k^\\star = 1 \\mid C = c_2) \\approx 0 Pr(Xk‚ãÜ=0‚à£C=c2)‚âà1\\Pr(X_k^\\star = 0 \\mid C = c_2) \\approx 1 simplifies : Pr(Xj=1‚à£C=c1)‚âàPr(Xj=1‚à£Xk‚ãÜ=1) \\Pr(X_j = 1 \\mid C = c_1) \\approx \\Pr(X_j = 1 \\mid X_k^\\star = 1) Let‚Äôs verify . Correct! Connection Correlations relationship Pr(Xj=1‚à£Xk‚ãÜ)\\Pr(X_j = 1 \\mid X_k^\\star) correlations becomes clear consider bivariate normal copula underlying binary data generation process. binary variables generated bivariate normal correlation œÅjk‚ãÜ\\rho_{jk^\\star}, : Pr(Xj=1‚à£Xk‚ãÜ=1)=Œ¶2(Œ¶‚àí1(pj),Œ¶‚àí1(pk‚ãÜ);œÅjk‚ãÜ)/pk‚ãÜ \\Pr(X_j = 1 \\mid X_k^\\star = 1) = \\Phi_2\\left(\\Phi^{-1}(p_j), \\Phi^{-1}(p_{k}^\\star); \\rho_{jk}^\\star \\right) / p_{k}^\\star IMPROVE, JOINT PROBABILITY BIVARIATE CDF pjp_j pk‚ãÜp_{k}^\\star marginal probabilities, Œ¶2\\Phi_2 bivariate standard normal CDF. Visualization Relationship Summary analysis demonstrates attention focused single feature prototype-based classification: Conditional Independence: features become conditionally independent category given exclusive feature: Xj‚ä•C‚à£Xk‚ãÜX_j \\perp C \\mid X_k^\\star Simplified Conditional Probabilities: Pr(Xj=1‚à£C=c1)‚âàPr(Xj=1‚à£Xk‚ãÜ=1)\\Pr(X_j = 1 \\mid C = c_1) \\approx \\Pr(X_j = 1 \\mid X_k^\\star = 1) Pr(Xj=1‚à£C=c2)‚âàPr(Xj=1‚à£Xk‚ãÜ=0)\\Pr(X_j = 1 \\mid C = c_2) \\approx \\Pr(X_j = 1 \\mid X_k^\\star = 0) Linear Relationship Correlations: change probability Pr(Xj‚à£C)‚àíPr(Xj)\\Pr(X_j \\mid C) - \\Pr(X_j) approximately linear correlation œÅjk‚ãÜ\\rho_{jk^\\star} feature jj exclusive feature k‚ãÜk^\\star. Theoretical Foundation: relationship stems bivariate normal copula underlying binary data generation process, making prototype model‚Äôs behavior predictable interpretable. provides theoretical insight practical understanding prototype-based classification behaves extreme attention weighting scenarios.","code":"d_uncorr <- make_binary_data(marginals, diag(K), obs) d_uncorr #>  #> ‚îÄ‚îÄ Data ‚îÄ‚îÄ #>  #> 5000 obs. of  12 variables: #>  $ x1 : int  1 0 1 0 0 0 0 0 0 1 ... #>  $ x2 : int  0 1 0 0 0 1 1 0 1 1 ... #>  $ x3 : int  1 1 1 1 0 1 1 1 1 0 ... #>  $ x4 : int  1 1 1 1 0 1 1 1 0 0 ... #>  $ x5 : int  0 0 1 0 0 1 0 0 1 1 ... #>  $ x6 : int  0 1 0 0 1 1 0 1 1 0 ... #>  $ x7 : int  0 0 0 0 0 0 1 0 0 0 ... #>  $ x8 : int  0 0 1 0 0 0 1 0 1 0 ... #>  $ x9 : int  0 0 1 0 0 0 0 0 0 0 ... #>  $ x10: int  0 0 0 0 1 1 0 0 0 0 ... #>  $ x11: int  0 0 1 1 0 0 0 0 0 0 ... #>  $ x12: int  0 0 1 0 1 0 0 0 0 0 ... #>  #> ‚îÄ‚îÄ Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginal Probabilities: #>   x1   x2   x3   x4   x5   x6   x7   x8   x9  x10  x11  x12  #> 0.32 0.58 0.72 0.61 0.40 0.46 0.20 0.51 0.20 0.21 0.18 0.25 #>  #>  #> ‚îÄ‚îÄ Correlation Matrix: #>     x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 #> x1   1  0  0  0  0  0  0  0  0   0   0   0 #> x2   0  1  0  0  0  0  0  0  0   0   0   0 #> x3   0  0  1  0  0  0  0  0  0   0   0   0 #> x4   0  0  0  1  0  0  0  0  0   0   0   0 #> x5   0  0  0  0  1  0  0  0  0   0   0   0 #> x6   0  0  0  0  0  1  0  0  0   0   0   0 #> x7   0  0  0  0  0  0  1  0  0   0   0   0 #> x8   0  0  0  0  0  0  0  1  0   0   0   0 #> x9   0  0  0  0  0  0  0  0  1   0   0   0 #> x10  0  0  0  0  0  0  0  0  0   1   0   0 #> x11  0  0  0  0  0  0  0  0  0   0   1   0 #> x12  0  0  0  0  0  0  0  0  0   0   0   1 uncorrelated <- compute(d_uncorr, prototypes, w, g) probs_uncorrelated <- summary(uncorrelated, s = 4e3) #> Joining with `by = join_by(x)` #> Joining with `by = join_by(x)` exclusive_feature <- colnames(sim_data)[which.max(w2)] exclusive_feature  sim_data |>   summarize(across(everything(), mean), .by = all_of(exclusive_feature))  probs_baseline$conditional$features bivariateCondProb(params, kstar = 3) |> round(3) probs_baseline$conditional$features |> round(3) # Show correlation coefficient cor_coef <- cor(comparison_data$correlation, comparison_data$change) cat(\"Correlation between œÅ and probability change:\", round(cor_coef, 3), \"\\n\")"},{"path":"https://acastroaraujo.github.io/protoClassification/articles/Correlations.html","id":"extra","dir":"Articles","previous_headings":"","what":"Extra","title":"Correlations","text":"Modifying correlation coefficient‚Ä¶ transform_rho ‚ä•BA \\perp B, P(‚à£B)=P()P(\\mid B) = P(), meaning difference quantities zero. Knowing category person belongs increaess decreases probability feature. MULTI MULTI SIMULATION Remember keep separate idea compositional effects changing compositions. Compositional effects come changes model parameters. Changing compositions come changes data parameters (marginals correlations)","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"andr√©s castro ara√∫jo. Author, maintainer.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"castro ara√∫jo (2025). protoClassification: Prototype Model Classification. R package version 0.1.0, https://github.com/acastroaraujo/protoClassification.","code":"@Manual{,   title = {protoClassification: Prototype Model of Classification},   author = {andr√©s {castro ara√∫jo}},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/acastroaraujo/protoClassification}, }"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"protoclassification","dir":"","previous_headings":"","what":"Prototype Model of Classification","title":"Prototype Model of Classification","text":"Install development version protoClassification GitHub :","code":"# install.packages(\"pak\") pak::pak(\"acastroaraujo/protoClassification\")"},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get Started","title":"Prototype Model of Classification","text":"simulate dataset need create decide couple things first. number KK dimensions. marginal probabilities dimension. correlation matrix dimensions. Generate data. Note. parameters stored params attribute output. can verify column means roughly correspond marginal probabilities. order verify data follows correlation structure rho calculate ‚Äútetrachoric correlation.‚Äù Additional stuff Prototype Classification Model: w vector attention weights k P list prototypes, one per category. g (gamma) sensitivity parameter. Calculate distance similarity one prototype time: Calculate distance, similarity, probabilities multiple prototypes time: consolidate() previous output single data frame easier visualization. Note. Since binary data implemented, difference Manhattan Euclidean distance!","code":"library(protoClassification) set.seed(1) K <- 6 # 1st step marginals <- rbeta(K, 2, 2) # 2nd step rho <- rlkjcorr(1, K, eta = 1) # 3rd step set.seed(1) sim_data <- make_binary_data(marginals, rho, obs = 1e3) sim_data #>  #> ‚îÄ‚îÄ Data ‚îÄ‚îÄ #>  #> 1000 obs. of  6 variables: #>  $ x1: int  0 1 0 1 0 1 0 1 0 1 ... #>  $ x2: int  0 1 0 1 1 1 0 1 1 1 ... #>  $ x3: int  0 1 1 0 1 0 0 0 1 0 ... #>  $ x4: int  1 1 1 1 1 1 1 1 1 1 ... #>  $ x5: int  1 1 1 1 0 0 1 1 1 1 ... #>  $ x6: int  0 1 0 0 1 0 0 1 0 1 ... #>  #> ‚îÄ‚îÄ Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginal Probabilities: #>   x1   x2   x3   x4   x5   x6  #> 0.33 0.55 0.27 0.88 0.59 0.28 #>  #>  #> ‚îÄ‚îÄ Correlation Matrix: #>       x1    x2    x3    x4    x5    x6 #> x1  1.00  0.22  0.29  0.15 -0.02  0.36 #> x2  0.22  1.00 -0.08 -0.21 -0.01  0.37 #> x3  0.29 -0.08  1.00 -0.75  0.34  0.08 #> x4  0.15 -0.21 -0.75  1.00 -0.20 -0.34 #> x5 -0.02 -0.01  0.34 -0.20  1.00 -0.03 #> x6  0.36  0.37  0.08 -0.34 -0.03  1.00 colMeans(sim_data) #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 psych::tetrachoric(sim_data)$rho #>             x1          x2          x3         x4          x5          x6 #> x1  1.00000000  0.23375492  0.28118697  0.1442114 -0.01192531  0.40365755 #> x2  0.23375492  1.00000000 -0.13315127 -0.1448709  0.03404136  0.38467926 #> x3  0.28118697 -0.13315127  1.00000000 -0.7612102  0.40485490  0.07792155 #> x4  0.14421140 -0.14487091 -0.76121019  1.0000000 -0.31759978 -0.34664697 #> x5 -0.01192531  0.03404136  0.40485490 -0.3175998  1.00000000 -0.08953172 #> x6  0.40365755  0.38467926  0.07792155 -0.3466470 -0.08953172  1.00000000 set.seed(1) w <- runif(K) w <- w / sum(w) g <- 10 d <- calculateDistSim(   data = sim_data,   P = rep(1, K),   w = w,   g = g )  str(d) #> 'data.frame':    1000 obs. of  2 variables: #>  $ distance  : num  0.655 0 0.477 0.457 0.145 ... #>  $ similarity: num  0.00143 1 0.00846 0.01035 0.23423 ... prototypes <- list(   P1 = rep(1, K),   P2 = rep(0, K),   P3 = rep(1:0, K / 2) )  g <- rep(10, 3)  out <- compute(sim_data, prototypes, w, g) out #>  #> ‚îÄ‚îÄ Output ‚îÄ‚îÄ #>  #>  $ distance      1000 obs. of  3 variables #>  $ similarity    1000 obs. of  3 variables #>  $ probabilities 1000 obs. of  3 variables #>  $ data          1000 obs. of  6 variables #>  #> ‚îÄ‚îÄ Prototypes ‚îÄ‚îÄ #>  #>  $ P1: num [1:6] 1 1 1 1 1 1 #>  $ P2: num [1:6] 0 0 0 0 0 0 #>  $ P3: int [1:6] 1 0 1 0 1 0 #>  #> ‚îÄ‚îÄ Distance ‚îÄ‚îÄ #>  #> Manhattan (r = 1) #>  #> ‚îÄ‚îÄ Sensitivity ‚îÄ‚îÄ #>  #> g1 g2 g3  #> 10 10 10 #>  #> ‚îÄ‚îÄ Attention Weights ‚îÄ‚îÄ #>  #>    w1    w2    w3    w4    w5    w6  #> 0.082 0.116 0.178 0.282 0.063 0.279 #>  #> ‚îÄ‚îÄ Marginal Probabilities ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ `colMeans(.$data)` #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 #>  #> ‚îÄ‚îÄ `colMeans(.$probabilities)` #>        C1        C2        C3  #> 0.3883449 0.4360664 0.1755887 d <- consolidate(out) str(d) #> 'data.frame':    1000 obs. of  15 variables: #>  $ prob1: num  0.0379 0.9988 0.212 0.5783 0.998 ... #>  $ prob2: num  8.45e-01 4.53e-05 1.34e-01 2.45e-01 8.26e-04 ... #>  $ prob3: num  0.11692 0.00115 0.65354 0.17654 0.00115 ... #>  $ sim1 : num  0.00143 1 0.00846 0.01035 0.23423 ... #>  $ sim2 : num  3.18e-02 4.54e-05 5.36e-03 4.39e-03 1.94e-04 ... #>  $ sim3 : num  0.0044 0.001149 0.026083 0.003159 0.000269 ... #>  $ dist1: num  0.655 0 0.477 0.457 0.145 ... #>  $ dist2: num  0.345 1 0.523 0.543 0.855 ... #>  $ dist3: num  0.543 0.677 0.365 0.576 0.822 ... #>  $ x1   : int  0 1 0 1 0 1 0 1 0 1 ... #>  $ x2   : int  0 1 0 1 1 1 0 1 1 1 ... #>  $ x3   : int  0 1 1 0 1 0 0 0 1 0 ... #>  $ x4   : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ x5   : int  1 1 1 1 0 0 1 1 1 1 ... #>  $ x6   : int  0 1 0 0 1 0 0 1 0 1 ..."},{"path":"https://acastroaraujo.github.io/protoClassification/index.html","id":"marginal-and-conditional-probabilities","dir":"","previous_headings":"","what":"Marginal and Conditional Probabilities","title":"Prototype Model of Classification","text":"far, single simulation requires marginal probabilities element ùê±\\mathbf{x} specified outset. relevant piece information get compute() function .$probabilities object, calculates probability given individual simulated dataset belong prototype categories. allows us calculate marginal probabilities category. ingenuity, can use information get conditional probabilities . Pr(Xk=1‚à£C=c) \\Pr(X_k = 1 \\mid C = c) Pr(Xk=0‚à£C=c) \\Pr(X_k = 0 \\mid C = c) Pr(C=c‚à£Xk) \\Pr(C = c \\mid X_k) Alternatively, ‚Äôs easier use summary() function extract conditional marginal probabilities.","code":"colMeans(out$data) # cf. `marginals` argument in `make_binary_data()` #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 colMeans(out$probabilities) #>        C1        C2        C3  #> 0.3883449 0.4360664 0.1755887 conditionalProbs(out, \"features\") #>           x1        x2         x3        x4        x5         x6 #> C1 0.5226571 0.7802353 0.32826487 0.9332301 0.6171392 0.62588499 #> C2 0.1302299 0.4297247 0.05791891 0.9465871 0.4820181 0.03806980 #> C3 0.3770770 0.3621551 0.69020964 0.7052639 0.7862111 0.08786438 1 - conditionalProbs(out, \"features\") #>           x1        x2        x3         x4        x5        x6 #> C1 0.4769570 0.2200126 0.6714007 0.06717440 0.3829206 0.3734904 #> C2 0.8703417 0.5706125 0.9425701 0.05316343 0.5189671 0.9620408 #> C3 0.6227137 0.6362298 0.3103042 0.29413893 0.2117976 0.9130266 conditionalProbs(out, type = \"categories\") #> $`Xk=0` #>           C1        C2         C3 #> x1 0.2743383 0.5632908 0.16237092 #> x2 0.1926099 0.5577848 0.24960538 #> x3 0.3591157 0.5664215 0.07446281 #> x4 0.2566337 0.2286733 0.51469307 #> x5 0.3608689 0.5489563 0.09017476 #> x6 0.2001655 0.5788414 0.22099310 #>  #> $`Xk=1` #>           C1         C2         C3 #> x1 0.6236135 0.17344785 0.20293865 #> x2 0.5456643 0.33832130 0.11601444 #> x3 0.4652701 0.09116788 0.44356204 #> x4 0.4029833 0.45951724 0.13749944 #> x5 0.4073537 0.35719728 0.23544898 #> x6 0.8839345 0.06015273 0.05591273 probs <- summary(out) probs #>  #> ‚îÄ‚îÄ Categories ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginals: #>    C1    C2    C3  #> 0.388 0.436 0.176 #>  #> ‚îÄ‚îÄ Conditionals: #> $`Xk=0` #>       C1    C2    C3 #> x1 0.276 0.562 0.162 #> x2 0.193 0.558 0.249 #> x3 0.360 0.565 0.075 #> x4 0.258 0.231 0.511 #> x5 0.362 0.548 0.091 #> x6 0.202 0.578 0.220 #>  #> $`Xk=1` #>       C1    C2    C3 #> x1 0.624 0.173 0.202 #> x2 0.548 0.337 0.116 #> x3 0.467 0.092 0.441 #> x4 0.404 0.458 0.137 #> x5 0.409 0.357 0.234 #> x6 0.884 0.060 0.056 #>  #> ‚îÄ‚îÄ Features ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginals: #>    x1    x2    x3    x4    x5    x6  #> 0.326 0.554 0.274 0.899 0.588 0.275 #>  #> ‚îÄ‚îÄ Conditionals: #>       x1    x2    x3    x4    x5    x6 #> C1 0.523 0.779 0.329 0.933 0.618 0.625 #> C2 0.129 0.429 0.057 0.946 0.480 0.038 #> C3 0.378 0.364 0.691 0.705 0.788 0.088"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/bivariateCondProb.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract theoretical conditional probabilities for bivariate case ‚Äî bivariateCondProb","title":"Extract theoretical conditional probabilities for bivariate case ‚Äî bivariateCondProb","text":"Computes theoretical conditional probabilities P(X_j = 1 | C = c1) variables j attention focused entirely variable k*. case, P(X_j = 1 | C = c1) = P(X_j = 1 | X_k* = 1) uses bivariate normal distribution compute exact conditional probabilities based correlation structure.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/bivariateCondProb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract theoretical conditional probabilities for bivariate case ‚Äî bivariateCondProb","text":"","code":"bivariateCondProb(parameters, kstar)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/bivariateCondProb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract theoretical conditional probabilities for bivariate case ‚Äî bivariateCondProb","text":"parameters list containing marginal probabilities correlation matrix, returned get_data_params. kstar Integer. index variable receiving attention (must 1 number variables)","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/bivariateCondProb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract theoretical conditional probabilities for bivariate case ‚Äî bivariateCondProb","text":"named numeric vector conditional probabilities P(X_j = 1 | X_k* = 1)   variables j, variable position kstar   probability 1 (since X_k* = 1 conditioning event)","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate distances and similarity. ‚Äî calculateDistSim","title":"Calculate distances and similarity. ‚Äî calculateDistSim","text":"Calculate distances similarity features prototype. compute function multiple prototypes.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate distances and similarity. ‚Äî calculateDistSim","text":"","code":"calculateDistSim(data, P, w, g, r = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate distances and similarity. ‚Äî calculateDistSim","text":"data data frame, returned `make_data()` function P K-sized vector binary features (.e., prototype) w K-sized vector attention weights g sensitivity parameter, number larger zero r type distance, 1 Manhattan, 2 Euclidean","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/calculateDistSim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate distances and similarity. ‚Äî calculateDistSim","text":"data frame distance similarity","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compositionalEffect.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Compositional Effects by Modifying Model Parameters ‚Äî compositionalEffect","title":"Compare Compositional Effects by Modifying Model Parameters ‚Äî compositionalEffect","text":"Computes difference conditional probabilities relative risk ratios baseline prototype computation modified version specific parameters changed. function provides streamlined way analyze changes attention weights, sensitivity parameters, prototype definitions affect resulting probability distributions category assignments.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compositionalEffect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Compositional Effects by Modifying Model Parameters ‚Äî compositionalEffect","text":"","code":"compositionalEffect(baseline, ..., s = 1000)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compositionalEffect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Compositional Effects by Modifying Model Parameters ‚Äî compositionalEffect","text":"baseline prototypeComputation object, created compute. serves baseline condition specific parameters modified comparison. ... Named arguments specifying parameters modify. Must one : w K-sized numeric vector attention weights. Must sum     1 values must non-negative. g numeric vector sensitivity parameters, one per     prototype. values must non-negative (>= 0). prototypes list prototype vectors. prototype     must binary vector length number features     baseline data. parameters (data, distance type) inherited baseline. s Integer. Number draws sample probability estimation. Default 1000. Higher values provide precision increase computation time.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compositionalEffect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Compositional Effects by Modifying Model Parameters ‚Äî compositionalEffect","text":"compositionalEffect object (inherits list)   containing two data frames: diff Data frame probability differences       (comparison - baseline). Positive values indicate higher probabilities       modified condition, negative values indicate lower probabilities. rr Data frame relative risk ratios       (comparison / baseline). Values > 1 indicate higher relative probability       modified condition, values < 1 indicate lower relative probability,       values = 1 indicate change. data frames rows representing categories columns representing   features.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compositionalEffect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare Compositional Effects by Modifying Model Parameters ‚Äî compositionalEffect","text":"function creates modified prototype computation : Taking baseline computation's data parameters Replacing specified parameters new values provided ... Computing new prototype analysis compute Comparing conditional feature probabilities P(X|C) baseline modified versions comparison metrics computed : Difference: modified_prob - baseline_prob Relative Risk: modified_prob / baseline_prob approach allows systematic sensitivity analysis modifying one parameter time holding others constant.","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Distances and Similarities to Multiple Prototypes ‚Äî compute","title":"Calculate Distances and Similarities to Multiple Prototypes ‚Äî compute","text":"Calculates distances similarity scores set observations single prototype using weighted distance metrics. function implements core distance similarity calculations used prototype-based classification models.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Distances and Similarities to Multiple Prototypes ‚Äî compute","text":"","code":"compute(data, prototypes, w, g, r = 1L)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Distances and Similarities to Multiple Prototypes ‚Äî compute","text":"data data frame binary features (0s 1s), returned make_binary_data. row represents observation column represents binary feature. prototypes list prototype vectors. must length number columns data contain binary values (0 1). w numeric vector attention weights, one feature. Must : Length Equal length(P) ncol(data) Values Non-negative sum 1 g numeric sensitivity parameter controlling steepness similarity function. Must non-negative (>= 0). Higher values make similarity function sensitive distances. r Integer specifying distance metric type. Note irrelevant working binary data. 1 Manhattan distance (L1 norm) 2 Euclidean distance (L2 norm)","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Distances and Similarities to Multiple Prototypes ‚Äî compute","text":"data frame nrow(data) rows two columns: distance Numeric vector weighted distances       observation prototype similarity Numeric vector similarity scores, computed       exp(-g * distance) prototypeComputation object containing: distance Data frame distances observation       prototype similarity Data frame similarity scores       observation prototype probabilities Data frame category membership probabilities data original input data object also stores input parameters attributes.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/compute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Distances and Similarities to Multiple Prototypes ‚Äî compute","text":"function implements prototype-based categorization model : 1. **Distance Calculation**: observation \\(x\\) prototype \\(P_j\\):    $$d(x, P_j) = \\sum_{k=1}^{K} w_k |x_k - P_{j,k}|^r$$ 2. **Similarity Calculation**:    $$s(x, P_j) = \\exp(-g_j \\cdot d(x, P_j))$$ 3. **Probability Calculation**:    $$P(C_j|x) = \\frac{s(x, P_j)}{\\sum_{=1}^{n} s(x, P_i)}$$","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Conditional Probabilities from Prototype Model ‚Äî conditionalProbs","title":"Calculate Conditional Probabilities from Prototype Model ‚Äî conditionalProbs","text":"Computes point estimates conditional probabilities prototype computation, either P(X|C) (feature probabilities given categories) P(C|X) (category probabilities given feature values). function provides expected values conditional probability distributions.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Conditional Probabilities from Prototype Model ‚Äî conditionalProbs","text":"","code":"conditionalProbs(x, type = c(\"features\", \"categories\"), s = 500)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Conditional Probabilities from Prototype Model ‚Äî conditionalProbs","text":"x prototypeComputation object created compute. type Character string specifying type conditional probabilities: \"features\" Returns P(X|C) - probability features given categories \"categories\" Returns P(C|X) - probability categories given feature values s Integer. Number posterior draws used sampling-based estimation. Default 500. Results averaged across draws provide point estimates.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Conditional Probabilities from Prototype Model ‚Äî conditionalProbs","text":"return structure depends type parameter: type = \"features\":   data frame categories rows features columns, cell   contains P(X_k = 1 | C_j). get P(X_k = 0 | C_j) can calculate 1 - \"data frame\". type = \"categories\":   list two elements: Xk=0 Matrix P(C_j | X_k = 0) feature k category j Xk=1 Matrix P(C_j | X_k = 1) feature k category j","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Conditional Probabilities from Prototype Model ‚Äî conditionalProbs","text":"function provides point estimates taking mean sampling distributions generated conditionalProbsSample. conditional probabilities represent: P(X|C): Given observation belongs category C,     probability feature X value 1? P(C|X): Given feature X specific value (0 1),     probability observation belongs category C?","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Conditional Probabilities from Prototype Model ‚Äî conditionalProbsSample","title":"Sample Conditional Probabilities from Prototype Model ‚Äî conditionalProbsSample","text":"Generates posterior draws conditional probabilities prototype computation, either P(X|C) (feature probabilities given categories) P(C|X) (category probabilities given feature values). function primarily used internally functions can useful uncertainty quantification.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Conditional Probabilities from Prototype Model ‚Äî conditionalProbsSample","text":"","code":"conditionalProbsSample(x, type = c(\"features\", \"categories\"), s = 500)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Conditional Probabilities from Prototype Model ‚Äî conditionalProbsSample","text":"x prototypeComputation object created compute. type Character string specifying type conditional probabilities: \"features\" Returns P(X|C) - probability features given categories \"categories\" Returns P(C|X) - probability categories given feature values s Integer. Number posterior draws sample. Default 500. Higher values provide stable estimates increase computation time.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Conditional Probabilities from Prototype Model ‚Äî conditionalProbsSample","text":"return structure depends type parameter: type = \"features\":   list one element per category, element s √ó K   matrix feature probabilities (K = number features). type = \"categories\":   list one element per feature, element   s √ó n_categories √ó 2 array showing category probabilities   feature values 0 1.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/conditionalProbsSample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Conditional Probabilities from Prototype Model ‚Äî conditionalProbsSample","text":"function implements sampling-based approach estimate conditional probabilities: 1. observation, sample category assignments based computed    membership probabilities 2. Repeat process s times create multiple datasets 3. Calculate conditional probabilities sampled dataset approach captures uncertainty category assignments provides distribution conditional probability estimates rather point estimates.","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":null,"dir":"Reference","previous_headings":"","what":"Consolidate Prototype Computation Results ‚Äî consolidate","title":"Consolidate Prototype Computation Results ‚Äî consolidate","text":"Combines components prototype computation (probabilities, similarities, distances, original data) single data frame easier analysis export.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consolidate Prototype Computation Results ‚Äî consolidate","text":"","code":"consolidate(x)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consolidate Prototype Computation Results ‚Äî consolidate","text":"x prototypeComputation object created compute.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/consolidate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consolidate Prototype Computation Results ‚Äî consolidate","text":"data frame containing: Probability columns Named prob1, prob2, etc.,       representing category membership probabilities Similarity columns Named sim1, sim2, etc.,       representing similarity scores prototype Distance columns Named dist1, dist2, etc.,       representing distances prototype Feature columns Original binary feature data number probability, similarity, distance columns equals   number prototypes.","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/get_data_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parameters from prototypeData object ‚Äî get_data_params","title":"Extract parameters from prototypeData object ‚Äî get_data_params","text":"Retrieves parameters (marginal probabilities correlation matrix) used generate prototypeData object.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/get_data_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parameters from prototypeData object ‚Äî get_data_params","text":"","code":"get_data_params(x)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/get_data_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parameters from prototypeData object ‚Äî get_data_params","text":"x prototypeData object created make_binary_data","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/get_data_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract parameters from prototypeData object ‚Äî get_data_params","text":"list two components: marginals Named numeric vector marginal probabilities rho Correlation matrix used generate data","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Correlated Binary Data ‚Äî make_binary_data","title":"Make Correlated Binary Data ‚Äî make_binary_data","text":"Generates correlated binary data. function first generates multivariate normal data specified correlations, transforms binary data preserving correlation structure. Apparently known \"Gaussian copula\" approach.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Correlated Binary Data ‚Äî make_binary_data","text":"","code":"make_binary_data(marginals, rho, obs = 1000)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Correlated Binary Data ‚Äî make_binary_data","text":"marginals numeric vector marginal probabilities variable. rho symmetric correlation matrix dimensions matching length marginals obs Integer. Number observations (rows) generate.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Correlated Binary Data ‚Äî make_binary_data","text":"prototypeData object containing: Binary data data frame obs rows length(marginals) columns params attribute List containing original marginals correlation matrix","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/make_binary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make Correlated Binary Data ‚Äî make_binary_data","text":"","code":"# Generate 8-dimensional correlated binary data K <- 8 marginals <- rbeta(K, 2, 3) rho <- rlkjcorr(1, K, eta = 1 / 4) out <- make_binary_data(marginals, rho) out #>  #> ‚îÄ‚îÄ Data ‚îÄ‚îÄ #>  #> 1000 obs. of  8 variables: #>  $ x1: int  1 0 0 0 0 1 0 0 0 0 ... #>  $ x2: int  1 0 1 0 0 0 1 0 0 1 ... #>  $ x3: int  0 0 0 0 0 0 0 0 0 0 ... #>  $ x4: int  0 0 0 1 1 0 0 0 0 1 ... #>  $ x5: int  0 1 0 1 1 1 1 0 0 1 ... #>  $ x6: int  1 1 1 0 0 0 1 1 1 1 ... #>  $ x7: int  0 0 0 0 0 0 0 0 0 0 ... #>  $ x8: int  0 1 1 0 0 0 0 0 1 0 ... #>  #>  #> ‚îÄ‚îÄ Parameters ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Marginal Probabilities:  #>   x1   x2   x3   x4   x5   x6   x7   x8  #> 0.12 0.47 0.03 0.40 0.56 0.70 0.07 0.34  #>  #>  #> ‚îÄ‚îÄ Correlation Matrix:  #>       x1    x2    x3    x4    x5    x6    x7    x8 #> x1  1.00 -0.11  0.20  0.07  0.33  0.32  0.07 -0.19 #> x2 -0.11  1.00  0.63 -0.25 -0.59  0.78  0.09  0.66 #> x3  0.20  0.63  1.00 -0.19 -0.09  0.57  0.54  0.42 #> x4  0.07 -0.25 -0.19  1.00  0.35 -0.56 -0.02 -0.54 #> x5  0.33 -0.59 -0.09  0.35  1.00 -0.45  0.12 -0.52 #> x6  0.32  0.78  0.57 -0.56 -0.45  1.00 -0.14  0.58 #> x7  0.07  0.09  0.54 -0.02  0.12 -0.14  1.00  0.22 #> x8 -0.19  0.66  0.42 -0.54 -0.52  0.58  0.22  1.00"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.compositionalEffect.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for compositionalEffect objects ‚Äî print.compositionalEffect","title":"Print method for compositionalEffect objects ‚Äî print.compositionalEffect","text":"Displays formatted summary effects parameter modifications prototype computations, showing changes category marginal probabilities, probability differences, relative risk ratios.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.compositionalEffect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for compositionalEffect objects ‚Äî print.compositionalEffect","text":"","code":"# S3 method for class 'compositionalEffect' print(x, ...)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.compositionalEffect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for compositionalEffect objects ‚Äî print.compositionalEffect","text":"x compositionalEffect object created compositionalEffect. ... Additional arguments passed print methods (currently unused).","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.compositionalEffect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for compositionalEffect objects ‚Äî print.compositionalEffect","text":"Invisibly returns input object x","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.compositionalEffect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print method for compositionalEffect objects ‚Äî print.compositionalEffect","text":"print method displays: Category Marginal Probabilities Shows marginal category probabilities     parameter modification, computed column means     probability matrices Œî Probs probability differences (modified - baseline)     feature within category. Positive values indicate higher probabilities     modified condition Risk Ratio relative risk ratios (modified / baseline)     feature within category. Values > 1 indicate higher relative probability     modified condition, values < 1 indicate lower relative probability numeric values rounded 3 decimal places readability.","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeComputation.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for prototypeComputation objects ‚Äî print.prototypeComputation","title":"Print method for prototypeComputation objects ‚Äî print.prototypeComputation","text":"Displays formatted summary prototypeComputation object, including data structure, prototypes, distance type, sensitivity parameters, attention weights, marginal probabilities.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeComputation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for prototypeComputation objects ‚Äî print.prototypeComputation","text":"","code":"# S3 method for class 'prototypeComputation' print(x, ...)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeComputation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for prototypeComputation objects ‚Äî print.prototypeComputation","text":"x prototypeComputation object created compute. ... Additional arguments passed print methods (currently unused).","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeComputation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for prototypeComputation objects ‚Äî print.prototypeComputation","text":"Invisibly returns input object x.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeData.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for prototypeData objects ‚Äî print.prototypeData","title":"Print method for prototypeData objects ‚Äî print.prototypeData","text":"Displays formatted summary prototypeData object, showing data structure parameters used generate (marginal probabilities correlation matrix).","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for prototypeData objects ‚Äî print.prototypeData","text":"","code":"# S3 method for class 'prototypeData' print(x, digits = 2, ...)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.prototypeData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for prototypeData objects ‚Äî print.prototypeData","text":"x prototypeData object created make_binary_data digits Integer. Number decimal places display numeric values (default: 2) ... Currently unused.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.summary.prototypeComputation.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Summary Statistics for Prototype Computation Objects ‚Äî print.summary.prototypeComputation","title":"Print Summary Statistics for Prototype Computation Objects ‚Äî print.summary.prototypeComputation","text":"Displays formatted summary prototype-based classification results, showing marginal conditional probability distributions categories features. method provides comprehensive overview prototype model distributes probability mass across categories features.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.summary.prototypeComputation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Summary Statistics for Prototype Computation Objects ‚Äî print.summary.prototypeComputation","text":"","code":"# S3 method for class 'summary.prototypeComputation' print(x, ...)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.summary.prototypeComputation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Summary Statistics for Prototype Computation Objects ‚Äî print.summary.prototypeComputation","text":"x summary.prototypeComputation object created summary.prototypeComputation. ... Additional arguments passed print methods (currently unused).","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.summary.prototypeComputation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Summary Statistics for Prototype Computation Objects ‚Äî print.summary.prototypeComputation","text":"Invisibly returns input object x unchanged. function   called primarily side effect printing formatted output.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/print.summary.prototypeComputation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Summary Statistics for Prototype Computation Objects ‚Äî print.summary.prototypeComputation","text":"printed output organized two main sections: Categories Section: Marginals: Overall probability assignment category     across observations, computed colMeans(object$probabilities) Conditionals: Two sub-lists showing P(C|X) - probability     category given feature values: Xk=0: Category probabilities feature equals 0 Xk=1: Category probabilities feature equals 1 Features Section: Marginals: Overall probability feature equals 1     across observations, computed colMeans(object$data) Conditionals: probability feature equals 1     given membership category, P(X|C). probability values rounded 3 decimal places readability.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"Generates random correlation matrices LKJ (Lewandowski-Kurowicka-Joe) distribution. LKJ distribution prior distribution correlation matrices generalizes uniform distribution correlation matrices. eta increases, probability mass concentrated around identity matrix.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"","code":"rlkjcorr(n, K, eta = 1)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"functions come Richard McElreath's rethinking package , judging source code, seems got Ben Goodrich.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"n Integer. Number correlation matrices generate K Integer. Dimension correlation matrix (number rows/columns). Must least 2 eta Numeric. Shape parameter controlling concentration around identity matrix. Must positive. eta = 1, distribution uniform correlation matrices. eta increases, mass placed matrices closer identity matrix","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"n = 1, returns single K√óK correlation matrix.   n > 1, returns list n correlation matrices.   matrices symmetric positive definite 1s diagonal.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"Lewandowski, D., Kurowicka, D., & Joe, H. (2009). Generating random correlation matrices based vines extended onion method. Journal multivariate analysis, 100(9), 1989-2001.","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/rlkjcorr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate random correlation matrices from the LKJ distribution ‚Äî rlkjcorr","text":"","code":"# Generate a single 4x4 correlation matrix rho1 <- rlkjcorr(n = 1, K = 4, eta = 1) round(rho1, 2) #>       [,1]  [,2]  [,3]  [,4] #> [1,]  1.00 -0.24 -0.37 -0.48 #> [2,] -0.24  1.00  0.80  0.15 #> [3,] -0.37  0.80  1.00  0.33 #> [4,] -0.48  0.15  0.33  1.00  # Generate 5 correlation matrices with more concentration around identity rho_list <- rlkjcorr(n = 5, K = 3, eta = 4) lapply(rho_list, round, 2) #> [[1]] #>      [,1] [,2] [,3] #> [1,] 1.00 0.39 0.21 #> [2,] 0.39 1.00 0.16 #> [3,] 0.21 0.16 1.00 #>  #> [[2]] #>       [,1]  [,2]  [,3] #> [1,]  1.00 -0.66  0.44 #> [2,] -0.66  1.00 -0.24 #> [3,]  0.44 -0.24  1.00 #>  #> [[3]] #>       [,1]  [,2] [,3] #> [1,]  1.00 -0.37 0.32 #> [2,] -0.37  1.00 0.11 #> [3,]  0.32  0.11 1.00 #>  #> [[4]] #>       [,1] [,2]  [,3] #> [1,]  1.00 0.05 -0.17 #> [2,]  0.05 1.00  0.06 #> [3,] -0.17 0.06  1.00 #>  #> [[5]] #>      [,1]  [,2]  [,3] #> [1,] 1.00  0.01  0.40 #> [2,] 0.01  1.00 -0.31 #> [3,] 0.40 -0.31  1.00 #>"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/summary.prototypeComputation.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Prototype Computation Objects ‚Äî summary.prototypeComputation","title":"Summary Method for Prototype Computation Objects ‚Äî summary.prototypeComputation","text":"Computes returns comprehensive summary statistics prototypeComputation object, including marginal conditional probabilities categories features. provides complete statistical overview prototype model results.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/summary.prototypeComputation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Prototype Computation Objects ‚Äî summary.prototypeComputation","text":"","code":"# S3 method for class 'prototypeComputation' summary(object, s = 500, ...)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/summary.prototypeComputation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Prototype Computation Objects ‚Äî summary.prototypeComputation","text":"object prototypeComputation object created compute. s Integer. Number draws sample probabilities computing conditional probabilities. Default 500. Higher values provide stable estimates. ... Additional arguments (currently unused).","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/summary.prototypeComputation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for Prototype Computation Objects ‚Äî summary.prototypeComputation","text":"summary.prototypeComputation object containing: marginal List marginal probabilities: categories: Vector category marginal probabilities features: Vector feature marginal probabilities  conditional List conditional probabilities: categories: P(C|X) feature values 0 1 features: P(X|C) matrix","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/summary.prototypeComputation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Method for Prototype Computation Objects ‚Äî summary.prototypeComputation","text":"summary provides four key probability distributions: Category Marginals: Overall probability category     across observations Feature Marginals: Overall probability feature     1 across observations Conditional Features: P(X_k = 1 | C_j) feature k     category j Conditional Categories: P(C_j | X_k = 0) P(C_j | X_k = 1)     category j feature k","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":null,"dir":"Reference","previous_headings":"","what":"Temperature Scaling for Probability Distributions ‚Äî temperature","title":"Temperature Scaling for Probability Distributions ‚Äî temperature","text":"Applies temperature scaling probability distribution using softmax function.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temperature Scaling for Probability Distributions ‚Äî temperature","text":"","code":"temperature(w, temp)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temperature Scaling for Probability Distributions ‚Äî temperature","text":"w numeric vector probabilities must sum 1. values must 0 1 (inclusive). function validate sum equals 1 within floating-point precision (tolerance 1e-10). temp single numeric value specifying temperature parameter. Must non-negative (>= 0). temp > 1: Makes distribution uniform (smoother, less peaked) temp < 1: Makes distribution less uniform (sharper, peaked) temp = 1: change original distribution temp = 0: Returns vector 1 position maximum probability 0 otherwise","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temperature Scaling for Probability Distributions ‚Äî temperature","text":"numeric vector length w containing temperature-scaled   probabilities. returned vector sum 1 values 0 1.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/temperature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temperature Scaling for Probability Distributions ‚Äî temperature","text":"","code":"w <- runif(4) w <- w / sum(w)  w #> [1] 0.01373785 0.13930836 0.22925414 0.61769965  temperature(w, temp = 0) #> [1] 0 0 0 1 temperature(w, temp = 0.5) #> [1] 0.0004159713 0.0427740085 0.1158403779 0.8409696423 temperature(w, temp = 1) #> [1] 0.01373785 0.13930836 0.22925414 0.61769965"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","title":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","text":"Modifies correlation matrix setting specific -diagonal elements desired values, adjusts matrix ensure remains positive definite. useful creating correlation matrices specific patterns maintaining mathematical validity.","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","text":"","code":"transform_rho(rho, el)"},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","text":"rho correlation matrix el matrix 3 columns specifying transformations apply: Column 1 Row indices () correlations modify Column 2 Column indices (j) correlations modify Column 3 New correlation values set rho[,j] correlation values must -1 1","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","text":"transformed correlation matrix positive definite.   function automatically ensures symmetry (sets rho[,j] rho[j,])   uses nearPD find nearest positive definite matrix   specified correlations make matrix non-positive definite","code":""},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","text":"function first sets specified correlations symmetric positions matrix, uses nearPD function Matrix package find nearest positive definite correlation matrix. Information convergence printed console.","code":""},{"path":[]},{"path":"https://acastroaraujo.github.io/protoClassification/reference/transform_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform correlation matrix by setting specific correlations ‚Äî transform_rho","text":"","code":"# Start with a random correlation matrix rho <- rlkjcorr(n = 1, K = 4, eta = 1) round(rho, 2) #>       [,1]  [,2]  [,3]  [,4] #> [1,]  1.00 -0.29 -0.61 -0.59 #> [2,] -0.29  1.00 -0.31 -0.15 #> [3,] -0.61 -0.31  1.00  0.91 #> [4,] -0.59 -0.15  0.91  1.00  # Define specific correlations to set el <- rbind(   c(i = 1, j = 2, r = +0.7), # Set correlation between variables 1 and 2 to 0.7   c(i = 3, j = 4, r = -0.5)  # Set correlation between variables 3 and 4 to -0.5 )  # Transform the matrix rho_new <- transform_rho(rho, el) #> iterations: 14 #> converged: TRUE round(rho_new, 2) #>       [,1]  [,2]  [,3]  [,4] #> [1,]  1.00  0.67 -0.53 -0.50 #> [2,]  0.67  1.00 -0.34 -0.17 #> [3,] -0.53 -0.34  1.00 -0.43 #> [4,] -0.50 -0.17 -0.43  1.00  # Verify the specified correlations were set rho_new[1, 2]  # Should be close to 0.7 #> [1] 0.6709284 rho_new[3, 4]  # Should be close to -0.5 #> [1] -0.4335107"}]
