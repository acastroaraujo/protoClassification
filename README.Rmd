---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# protoClassification

<!-- badges: start -->

[![R-CMD-check](https://github.com/acastroaraujo/protoClassification/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/acastroaraujo/protoClassification/actions/workflows/R-CMD-check.yaml)

<!-- badges: end -->

Install the development version of protoClassification from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("acastroaraujo/protoClassification")
```

## Get Started

To simulate a dataset you need to create to decide a couple of things first.

1.  The number of $K$ dimensions.
2.  The marginal probabilities for each dimension.
3.  A correlation matrix for the dimensions.

```{r}
library(protoClassification)
set.seed(1)
K <- 6 # 1st step
marginals <- rbeta(K, 2, 2) # 2nd step
rho <- rlkjcorr(1, K, eta = 1) # 3rd step

```

**Generate data.**

```{r}
set.seed(1)
sim_data <- make_binary_data(marginals, rho, obs = 1e3)
sim_data
```

*Note. The parameters are stored as the `params` attribute in the output.*

We can verify that the column means *roughly* correspond to the marginal probabilities.

```{r}
colMeans(sim_data)
```

In order to verify that the data follows the correlation structure in `rho` you would have to calculate a "[tetrachoric correlation](https://en.wikipedia.org/wiki/Polychoric_correlation)."

```{r, warning=FALSE}
psych::tetrachoric(sim_data)$rho
```

Additional stuff for Prototype Classification Model:

-   `w` a vector of attention weights for each k

-   `P` a list of prototypes, one per category.

-   `g` (gamma) sensitivity parameter.

```{r}
set.seed(1)
w <- runif(K)
w <- w / sum(w)
g <- 10
```

Calculate distance and similarity for one prototype at a time:

```{r}
d <- calculateDistSim(
  P = rep(1, K), 
  w = w, 
  data = sim_data, 
  g = g
)

str(d)
```

Calculate distance, similarity, and probabilities for multiple prototypes at the same time:

```{r}
prototypes <- list(
  P1 = rep(1, K),
  P2 = rep(0, K),
  P3 = rep(1:0, K / 2)
)

g <- rep(10, 3)

out <- compute(prototypes, w, sim_data, g = g, r = 1)
out
```

`consolidate()` the previous output into a single data frame for easier visualization.

```{r}
d <- consolidate(out)
str(d)
```

## Conditional Probabilities

**YOU ARE HERE**

The more relevant piece of information coming from the `compute()` function is the `.$probabilities` object.

```{r}
out$probabilities |> 
  head(n = 10)
```

With this you can classify each row in the simulated dataset and then get posterior conditional probabilities.

$$
\Pr(X_k = x \mid C = c)
$$

```{r}
conditionalProbsSample(out, type = "features", s = 3)
```

$$
\Pr(C = c \mid X_k = x)
$$

```{r}
conditionalProbsSample(out, type = "categories", s = 2)
```

Instead of working directly with the posterior draws, you can average over them using the `conditionalProbs()` function:

```{r}
conditionalProbs(out, type = "features", s = 300)
conditionalProbs(out, type = "categories", s = 300)
```

Alternatively, it's easier to use the `summary()` function to extract all conditional and marginal probabilities.

```{r}
probs <- summary(out)
probs
```

## Compositional Effects

YOU ARE HERE... EXPLAIN WHAT THEY ARE

$$
\Pr(\mathbf{x} \mid C_1)
$$

Bayes

$$
\Pr(x_1 \mid C_1) = \frac{\Pr(C_1 \mid x_1 = 1) \Pr(x_1 = 1)}{\Pr(C_1 \mid x_1 = 1) \Pr(x_1 = 1) + \Pr(C_1 \mid x_1 = 0) \Pr(x_1 = 0)}
$$

The point is to compare different probabilities across different parameters values (i.e., compositional effects).

For example:

```{r}

set.seed(1)
w_unif <- temperature(w, 5) # make weights more uniform
w_unif

out <- compute(prototypes, w_unif, sim_data, g, r = 1) 
summary(out)

w2 <- vector("double", length(w)) # all attention on dimension 2
w2[[2]] <- 1
w2

out <- compute(prototypes, w2, sim_data, g, r = 1)
summary(out)
```

------------------------------------------------------------------------

To do:

-   Figure out when "r = 1" or "r = 2" matters. It seems that Manhattan distance is used when the underlying data is binary. Since I'm only using binary data in these simulations, it seems that this doesn't matter, right?
-   Figure out a best way to measure compositional effects (e.g., relative risk ratio, difference in probabilities)

Change P to C when necessary.
